/******/ (function(modules) { // webpackBootstrap
/******/ 	// The module cache
/******/ 	var installedModules = {};
/******/
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/
/******/ 		// Check if module is in cache
/******/ 		if(installedModules[moduleId]) {
/******/ 			return installedModules[moduleId].exports;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = installedModules[moduleId] = {
/******/ 			i: moduleId,
/******/ 			l: false,
/******/ 			exports: {}
/******/ 		};
/******/
/******/ 		// Execute the module function
/******/ 		modules[moduleId].call(module.exports, module, module.exports, __webpack_require__);
/******/
/******/ 		// Flag the module as loaded
/******/ 		module.l = true;
/******/
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/
/******/
/******/ 	// expose the modules object (__webpack_modules__)
/******/ 	__webpack_require__.m = modules;
/******/
/******/ 	// expose the module cache
/******/ 	__webpack_require__.c = installedModules;
/******/
/******/ 	// define getter function for harmony exports
/******/ 	__webpack_require__.d = function(exports, name, getter) {
/******/ 		if(!__webpack_require__.o(exports, name)) {
/******/ 			Object.defineProperty(exports, name, {
/******/ 				configurable: false,
/******/ 				enumerable: true,
/******/ 				get: getter
/******/ 			});
/******/ 		}
/******/ 	};
/******/
/******/ 	// getDefaultExport function for compatibility with non-harmony modules
/******/ 	__webpack_require__.n = function(module) {
/******/ 		var getter = module && module.__esModule ?
/******/ 			function getDefault() { return module['default']; } :
/******/ 			function getModuleExports() { return module; };
/******/ 		__webpack_require__.d(getter, 'a', getter);
/******/ 		return getter;
/******/ 	};
/******/
/******/ 	// Object.prototype.hasOwnProperty.call
/******/ 	__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };
/******/
/******/ 	// __webpack_public_path__
/******/ 	__webpack_require__.p = "";
/******/
/******/ 	// Load entry module and return exports
/******/ 	return __webpack_require__(__webpack_require__.s = 0);
/******/ })
/************************************************************************/
/******/ ([
/* 0 */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nvar __assign = (this && this.__assign) || Object.assign || function(t) {\n    for (var s, i = 1, n = arguments.length; i < n; i++) {\n        s = arguments[i];\n        for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p))\n            t[p] = s[p];\n    }\n    return t;\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar common_1 = __webpack_require__(1);\nvar gzip = __webpack_require__(2);\nself.addEventListener('message', function (e) {\n    var request = e.data;\n    var mainThread = self;\n    try {\n        var hduSources = decode(request);\n        var response = {\n            requestId: request.requestId,\n            hduSources: hduSources,\n        };\n        mainThread.postMessage(response, hduSources.map(function (s) { return s.data; }));\n    }\n    catch (error) {\n        var response = {\n            requestId: request.requestId,\n            error: error,\n        };\n        mainThread.postMessage(response);\n    }\n});\nfunction decode(request) {\n    var raw = isGzipped(request.fileContent) ? gzipInflate(request.fileContent) : request.fileContent;\n    var _a = strideArrayBuffer(raw), headers = _a.headers, dataBuffers = _a.dataBuffers;\n    if (!request.hduDecodeOptions)\n        request.hduDecodeOptions = headers.map(function (h, i) { return ({ sourceIndex: i }); });\n    // fill omitted fields\n    for (var j = 0; j < request.hduDecodeOptions.length; ++j) {\n        var o = request.hduDecodeOptions[j];\n        var i = o.sourceIndex == undefined ? (o.sourceIndex = j) : o.sourceIndex;\n        var h = headers[i];\n        o.outputDataType == undefined && (o.outputDataType = common_1.DataType.float32);\n    }\n    return request.hduDecodeOptions.map(function (o) {\n        if (o.sourceIndex >= headers.length)\n            throw new Error(\"hdul.length(\" + headers.length + \") >= sourceIndex(\" + o.sourceIndex + \")\");\n        var header = headers[o.sourceIndex];\n        var buffer = dataBuffers[o.sourceIndex];\n        var ab = buildTypedArray(header, buffer, o);\n        return { header: header, data: ab, dataType: o.outputDataType };\n    });\n}\nfunction buildTypedArray(header, dv, o) {\n    var nPixels = calcDataSize(header).nPixels;\n    var bitpix = common_1.card(header, 'BITPIX', 'number');\n    var picker;\n    switch (bitpix) {\n        case 8:\n            picker = function (i) { return dv.getUint8(i); };\n            break;\n        case 16:\n            picker = function (i) { return dv.getUint16(i << 1); };\n            break;\n        case 32:\n            picker = function (i) { return dv.getUint32(i << 2); };\n            break;\n        case -32:\n            picker = function (i) { return dv.getFloat32(i << 2); };\n            break;\n        case -64:\n            picker = function (i) { return dv.getFloat64(i << 4); };\n            break;\n    }\n    var value = function (i) { return picker(i); };\n    if ([common_1.DataType.float32, common_1.DataType.float64].indexOf(o.outputDataType) >= 0) {\n        var bzero_1 = common_1.card(header, 'BZERO', 'number', 0);\n        var bscale_1 = common_1.card(header, 'BSCALE', 'number', 1);\n        value = function (i) { return bscale_1 * picker(i) + bzero_1; };\n    }\n    var outArrayFactory = (_a = {},\n        _a[common_1.DataType.uint8] = Uint8Array,\n        _a[common_1.DataType.uint16] = Uint16Array,\n        _a[common_1.DataType.uint32] = Uint32Array,\n        _a[common_1.DataType.float32] = Float32Array,\n        _a[common_1.DataType.float64] = Float64Array,\n        _a)[o.outputDataType];\n    var array = new outArrayFactory(nPixels);\n    for (var i = 0; i < nPixels; ++i)\n        array[i] = value(i);\n    return array.buffer;\n    var _a;\n}\nvar CARD_LENGTH = 80;\nvar CARDS_PER_BLOCK = 36;\nvar BLOCK_SIZE = CARD_LENGTH * CARDS_PER_BLOCK;\nfunction strideArrayBuffer(ab) {\n    var offset = 0;\n    var headers = [];\n    var dataBuffers = [];\n    for (var hduIndex = 0; offset < ab.byteLength; ++hduIndex) {\n        var header = {};\n        while (true) {\n            var blockBytes = new Uint8Array(ab, offset, BLOCK_SIZE);\n            offset += BLOCK_SIZE;\n            var _a = parseHeaderBlock(blockBytes), end = _a.end, newHeader = _a.header;\n            header = __assign({}, header, newHeader);\n            if (end)\n                break;\n        }\n        var byteLength = calcDataSize(header).byteLength;\n        headers.push(header);\n        dataBuffers.push(new DataView(ab, offset, byteLength));\n        offset += align(byteLength, BLOCK_SIZE);\n    }\n    return { headers: headers, dataBuffers: dataBuffers };\n}\nfunction bitpix2dataType(bitpix) {\n    switch (bitpix) {\n        case 8:\n            return common_1.DataType.uint8;\n        case 16:\n            return common_1.DataType.uint16;\n        case 32:\n            return common_1.DataType.uint32;\n        case -32:\n            return common_1.DataType.float32;\n        case -64:\n            return common_1.DataType.float64;\n        default:\n            throw new Error(\"unknwon BITPIX: \" + bitpix);\n    }\n}\nfunction align(n, blockSize) {\n    return (Math.floor((n - 1) / blockSize) + 1) * blockSize;\n}\nfunction calcDataSize(header) {\n    var naxis = common_1.card(header, 'NAXIS', 'number');\n    var naxes = range(1, naxis + 1).map(function (i) { return common_1.card(header, \"NAXIS\" + i, 'number'); });\n    var nPixels = naxes.reduce(function (memo, next) { return memo * next; }, 1);\n    var byteDepth = Math.abs(common_1.card(header, 'BITPIX', 'number')) / 8;\n    var byteLength = nPixels * byteDepth;\n    return { nPixels: nPixels, byteDepth: byteDepth, byteLength: byteLength, naxis: naxis, naxes: naxes };\n}\nfunction range(a, b) {\n    var array = [];\n    for (var i = a; i < b; ++i)\n        array.push(i);\n    return array;\n}\nfunction parseHeaderBlock(bytes) {\n    var text = String.fromCharCode.apply(String, bytes);\n    var header = {};\n    if (text.length != BLOCK_SIZE)\n        throw new Error(\"invalid byte sequence: \" + text);\n    var end = false;\n    cardLoop: for (var i = 0; i < CARDS_PER_BLOCK; ++i) {\n        var cardString = text.substr(i * CARD_LENGTH, CARD_LENGTH);\n        var card_1 = Card.parse(cardString);\n        switch (card_1.type) {\n            case CardType.END:\n                end = true;\n                break cardLoop;\n            case CardType.KEY_VALUE:\n                header[card_1.key] = card_1.value;\n                break;\n        }\n    }\n    return { end: end, header: header };\n}\nvar CardType;\n(function (CardType) {\n    CardType[CardType[\"END\"] = 0] = \"END\";\n    CardType[CardType[\"COMMENT\"] = 1] = \"COMMENT\";\n    CardType[CardType[\"HISTORY\"] = 2] = \"HISTORY\";\n    CardType[CardType[\"KEY_VALUE\"] = 3] = \"KEY_VALUE\";\n    CardType[CardType[\"UNKNOWN\"] = 4] = \"UNKNOWN\";\n})(CardType || (CardType = {}));\nvar Card = /** @class */ (function () {\n    function Card(type, _a) {\n        var _b = _a === void 0 ? {} : _a, key = _b.key, value = _b.value, comment = _b.comment;\n        this.type = type;\n        this.key = key;\n        this.value = value;\n        this.comment = comment;\n    }\n    Card.parse = function (raw) {\n        switch (raw.substr(0, 8)) {\n            case 'END     ':\n                return new Card(CardType.END);\n            case 'COMMENT ': {\n                var comment = strip(raw.substr(8));\n                return new Card(CardType.COMMENT, { comment: comment });\n            }\n            case 'HISTORY ': {\n                var comment = strip(raw.substr(8));\n                return new Card(CardType.HISTORY, { comment: comment });\n            }\n            default: {\n                var _a = raw.split('='), left = _a[0], right = _a[1];\n                if (!right) {\n                    return new Card(CardType.UNKNOWN);\n                }\n                if (left.match(/^HIERARCH /))\n                    left = left.substr(9);\n                var key = strip(left);\n                var _b = this.parseValueString(right), value = _b.value, comment = _b.comment;\n                return new Card(CardType.KEY_VALUE, { key: key, value: value, comment: comment });\n            }\n        }\n    };\n    Card.parseValueString = function (raw) {\n        var _a = raw.split('/'), valueString = _a[0], commentString = _a[1];\n        var comment;\n        if (commentString) {\n            comment = strip(commentString);\n        }\n        valueString = strip(valueString);\n        var value;\n        if (valueString == 'T')\n            value = true;\n        else if (valueString == 'F')\n            value = false;\n        else if (valueString.substr(0, 1) == \"'\") {\n            value = valueString.substring(1, valueString.length - 1);\n        }\n        else {\n            value = Number(valueString);\n        }\n        return { value: value, comment: comment };\n    };\n    return Card;\n}());\nfunction isGzipped(ab) {\n    var a = new Uint8Array(ab, 0, 2);\n    return a[0] == 0x1f && a[1] == 0x8b;\n}\nfunction gzipInflate(ab) {\n    return (new Uint8Array(gzip.unzip(new Uint8Array(ab)))).buffer;\n}\nfunction strip(s) {\n    return s.match(/\\s*(.*?)\\s*$/)[1];\n}\n\n\n//////////////////\n// WEBPACK FOOTER\n// ../node_modules/ts-loader!../src/decode_worker.ts\n// module id = 0\n// module chunks = 0\n\n//# sourceURL=webpack:///../src/decode_worker.ts?../node_modules/ts-loader");

/***/ }),
/* 1 */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar DataType;\n(function (DataType) {\n    DataType[DataType[\"uint8\"] = 0] = \"uint8\";\n    DataType[DataType[\"uint16\"] = 1] = \"uint16\";\n    DataType[DataType[\"uint32\"] = 2] = \"uint32\";\n    DataType[DataType[\"float32\"] = 3] = \"float32\";\n    DataType[DataType[\"float64\"] = 4] = \"float64\";\n})(DataType = exports.DataType || (exports.DataType = {}));\nfunction card(header, key, type, defaultValue) {\n    var value = header[key];\n    if (value == undefined)\n        value = defaultValue;\n    if (typeof value != type)\n        throw new Error(\"Type mismatch: \" + value + \" for \" + key);\n    return value;\n}\nexports.card = card;\n\n\n//////////////////\n// WEBPACK FOOTER\n// ../src/common.ts\n// module id = 1\n// module chunks = 0\n\n//# sourceURL=webpack:///../src/common.ts?");

/***/ }),
/* 2 */
/***/ (function(module, exports, __webpack_require__) {

eval("(function () {\n\t'use strict';\n\n\tvar crc32 = __webpack_require__(3),\n\t\tdeflate = __webpack_require__(4),\n\t\t// magic numbers marking this file as GZIP\n\t\tID1 = 0x1F,\n\t\tID2 = 0x8B,\n\t\tcompressionMethods = {\n\t\t\t'deflate': 8\n\t\t},\n\t\tpossibleFlags = {\n\t\t\t'FTEXT': 0x01,\n\t\t\t'FHCRC': 0x02,\n\t\t\t'FEXTRA': 0x04,\n\t\t\t'FNAME': 0x08,\n\t\t\t'FCOMMENT': 0x10\n\t\t},\n\t\tosMap = {\n\t\t\t'fat': 0, // FAT file system (DOS, OS/2, NT) + PKZIPW 2.50 VFAT, NTFS\n\t\t\t'amiga': 1, // Amiga\n\t\t\t'vmz': 2, // VMS (VAX or Alpha AXP)\n\t\t\t'unix': 3, // Unix\n\t\t\t'vm/cms': 4, // VM/CMS\n\t\t\t'atari': 5, // Atari\n\t\t\t'hpfs': 6, // HPFS file system (OS/2, NT 3.x)\n\t\t\t'macintosh': 7, // Macintosh\n\t\t\t'z-system': 8, // Z-System\n\t\t\t'cplm': 9, // CP/M\n\t\t\t'tops-20': 10, // TOPS-20\n\t\t\t'ntfs': 11, // NTFS file system (NT)\n\t\t\t'qdos': 12, // SMS/QDOS\n\t\t\t'acorn': 13, // Acorn RISC OS\n\t\t\t'vfat': 14, // VFAT file system (Win95, NT)\n\t\t\t'vms': 15, // MVS (code also taken for PRIMOS)\n\t\t\t'beos': 16, // BeOS (BeBox or PowerMac)\n\t\t\t'tandem': 17, // Tandem/NSK\n\t\t\t'theos': 18 // THEOS\n\t\t},\n\t\tos = 'unix',\n\t\tDEFAULT_LEVEL = 6;\n\n\tfunction putByte(n, arr) {\n\t\tarr.push(n & 0xFF);\n\t}\n\n\t// LSB first\n\tfunction putShort(n, arr) {\n\t\tarr.push(n & 0xFF);\n\t\tarr.push(n >>> 8);\n\t}\n\n\t// LSB first\n\tfunction putLong(n, arr) {\n\t\tputShort(n & 0xffff, arr);\n\t\tputShort(n >>> 16, arr);\n\t}\n\n\tfunction putString(s, arr) {\n\t\tvar i, len = s.length;\n\t\tfor (i = 0; i < len; i += 1) {\n\t\t\tputByte(s.charCodeAt(i), arr);\n\t\t}\n\t}\n\n\tfunction readByte(arr) {\n\t\treturn arr.shift();\n\t}\n\n\tfunction readShort(arr) {\n\t\treturn arr.shift() | (arr.shift() << 8);\n\t}\n\n\tfunction readLong(arr) {\n\t\tvar n1 = readShort(arr),\n\t\t\tn2 = readShort(arr);\n\n\t\t// JavaScript can't handle bits in the position 32\n\t\t// we'll emulate this by removing the left-most bit (if it exists)\n\t\t// and add it back in via multiplication, which does work\n\t\tif (n2 > 32768) {\n\t\t\tn2 -= 32768;\n\n\t\t\treturn ((n2 << 16) | n1) + 32768 * Math.pow(2, 16);\n\t\t}\n\n\t\treturn (n2 << 16) | n1;\n\t}\n\n\tfunction readString(arr) {\n\t\tvar charArr = [];\n\n\t\t// turn all bytes into chars until the terminating null\n\t\twhile (arr[0] !== 0) {\n\t\t\tcharArr.push(String.fromCharCode(arr.shift()));\n\t\t}\n\n\t\t// throw away terminating null\n\t\tarr.shift();\n\n\t\t// join all characters into a cohesive string\n\t\treturn charArr.join('');\n\t}\n\n\t/*\n\t * Reads n number of bytes and return as an array.\n\t *\n\t * @param arr- Array of bytes to read from\n\t * @param n- Number of bytes to read\n\t */\n\tfunction readBytes(arr, n) {\n\t\tvar i, ret = [];\n\t\tfor (i = 0; i < n; i += 1) {\n\t\t\tret.push(arr.shift());\n\t\t}\n\n\t\treturn ret;\n\t}\n\n\t/*\n\t * ZIPs a file in GZIP format. The format is as given by the spec, found at:\n\t * http://www.gzip.org/zlib/rfc-gzip.html\n\t *\n\t * Omitted parts in this implementation:\n\t */\n\tfunction zip(data, options) {\n\t\tvar flags = 0,\n\t\t\tlevel,\n\t\t\tcrc, out = [];\n\n\t\tif (!options) {\n\t\t\toptions = {};\n\t\t}\n\t\tlevel = options.level || DEFAULT_LEVEL;\n\n\t\tif (typeof data === 'string') {\n\t\t\tdata = Array.prototype.map.call(data, function (char) {\n\t\t\t\treturn char.charCodeAt(0);\n\t\t\t});\n\t\t}\n\n\t\t// magic number marking this file as GZIP\n\t\tputByte(ID1, out);\n\t\tputByte(ID2, out);\n\n\t\tputByte(compressionMethods['deflate'], out);\n\n\t\tif (options.name) {\n\t\t\tflags |= possibleFlags['FNAME'];\n\t\t}\n\n\t\tputByte(flags, out);\n\t\tputLong(options.timestamp || parseInt(Date.now() / 1000, 10), out);\n\n\t\t// put deflate args (extra flags)\n\t\tif (level === 1) {\n\t\t\t// fastest algorithm\n\t\t\tputByte(4, out);\n\t\t} else if (level === 9) {\n\t\t\t// maximum compression (fastest algorithm)\n\t\t\tputByte(2, out);\n\t\t} else {\n\t\t\tputByte(0, out);\n\t\t}\n\n\t\t// OS identifier\n\t\tputByte(osMap[os], out);\n\n\t\tif (options.name) {\n\t\t\t// ignore the directory part\n\t\t\tputString(options.name.substring(options.name.lastIndexOf('/') + 1), out);\n\n\t\t\t// terminating null\n\t\t\tputByte(0, out);\n\t\t}\n\n\t\tdeflate.deflate(data, level).forEach(function (byte) {\n\t\t\tputByte(byte, out);\n\t\t});\n\n\t\tputLong(parseInt(crc32(data), 16), out);\n\t\tputLong(data.length, out);\n\n\t\treturn out;\n\t}\n\n\tfunction unzip(data, options) {\n\t\t// start with a copy of the array\n\t\tvar arr = Array.prototype.slice.call(data, 0),\n\t\t\tt,\n\t\t\tcompressionMethod,\n\t\t\tflags,\n\t\t\tmtime,\n\t\t\txFlags,\n\t\t\tkey,\n\t\t\tos,\n\t\t\tcrc,\n\t\t\tsize,\n\t\t\tres;\n\n\t\t// check the first two bytes for the magic numbers\n\t\tif (readByte(arr) !== ID1 || readByte(arr) !== ID2) {\n\t\t\tthrow 'Not a GZIP file';\n\t\t}\n\n\t\tt = readByte(arr);\n\t\tt = Object.keys(compressionMethods).some(function (key) {\n\t\t\tcompressionMethod = key;\n\t\t\treturn compressionMethods[key] === t;\n\t\t});\n\n\t\tif (!t) {\n\t\t\tthrow 'Unsupported compression method';\n\t\t}\n\n\t\tflags = readByte(arr);\n\t\tmtime = readLong(arr);\n\t\txFlags = readByte(arr);\n\t\tt = readByte(arr);\n\t\tObject.keys(osMap).some(function (key) {\n\t\t\tif (osMap[key] === t) {\n\t\t\t\tos = key;\n\t\t\t\treturn true;\n\t\t\t}\n\t\t});\n\n\t\t// just throw away the bytes for now\n\t\tif (flags & possibleFlags['FEXTRA']) {\n\t\t\tt = readShort(arr);\n\t\t\treadBytes(arr, t);\n\t\t}\n\n\t\t// just throw away for now\n\t\tif (flags & possibleFlags['FNAME']) {\n\t\t\treadString(arr);\n\t\t}\n\n\t\t// just throw away for now\n\t\tif (flags & possibleFlags['FCOMMENT']) {\n\t\t\treadString(arr);\n\t\t}\n\n\t\t// just throw away for now\n\t\tif (flags & possibleFlags['FHCRC']) {\n\t\t\treadShort(arr);\n\t\t}\n\n\t\tif (compressionMethod === 'deflate') {\n\t\t\t// give deflate everything but the last 8 bytes\n\t\t\t// the last 8 bytes are for the CRC32 checksum and filesize\n\t\t\tres = deflate.inflate(arr.splice(0, arr.length - 8));\n\t\t}\n\n\t\tif (flags & possibleFlags['FTEXT']) {\n\t\t\tres = Array.prototype.map.call(res, function (byte) {\n\t\t\t\treturn String.fromCharCode(byte);\n\t\t\t}).join('');\n\t\t}\n\n\t\tcrc = readLong(arr);\n\t\tif (crc !== parseInt(crc32(res), 16)) {\n\t\t\tthrow 'Checksum does not match';\n\t\t}\n\n\t\tsize = readLong(arr);\n\t\tif (size !== res.length) {\n\t\t\tthrow 'Size of decompressed file not correct';\n\t\t}\n\n\t\treturn res;\n\t}\n\n\tmodule.exports = {\n\t\tzip: zip,\n\t\tunzip: unzip,\n\t\tget DEFAULT_LEVEL() {\n\t\t\treturn DEFAULT_LEVEL;\n\t\t}\n\t};\n}());\n\n\n//////////////////\n// WEBPACK FOOTER\n// ../node_modules/gzip-js/lib/gzip.js\n// module id = 2\n// module chunks = 0\n\n//# sourceURL=webpack:///../node_modules/gzip-js/lib/gzip.js?");

/***/ }),
/* 3 */
/***/ (function(module, exports) {

eval("(function () {\n\t'use strict';\n\n\tvar table = [],\n\t\tpoly = 0xEDB88320; // reverse polynomial\n\n\t// build the table\n\tfunction makeTable() {\n\t\tvar c, n, k;\n\n\t\tfor (n = 0; n < 256; n += 1) {\n\t\t\tc = n;\n\t\t\tfor (k = 0; k < 8; k += 1) {\n\t\t\t\tif (c & 1) {\n\t\t\t\t\tc = poly ^ (c >>> 1);\n\t\t\t\t} else {\n\t\t\t\t\tc = c >>> 1;\n\t\t\t\t}\n\t\t\t}\n\t\t\ttable[n] = c >>> 0;\n\t\t}\n\t}\n\n\tfunction strToArr(str) {\n\t\t// sweet hack to turn string into a 'byte' array\n\t\treturn Array.prototype.map.call(str, function (c) {\n\t\t\treturn c.charCodeAt(0);\n\t\t});\n\t}\n\n\t/*\n\t * Compute CRC of array directly.\n\t *\n\t * This is slower for repeated calls, so append mode is not supported.\n\t */\n\tfunction crcDirect(arr) {\n\t\tvar crc = -1, // initial contents of LFBSR\n\t\t\ti, j, l, temp;\n\n\t\tfor (i = 0, l = arr.length; i < l; i += 1) {\n\t\t\ttemp = (crc ^ arr[i]) & 0xff;\n\n\t\t\t// read 8 bits one at a time\n\t\t\tfor (j = 0; j < 8; j += 1) {\n\t\t\t\tif ((temp & 1) === 1) {\n\t\t\t\t\ttemp = (temp >>> 1) ^ poly;\n\t\t\t\t} else {\n\t\t\t\t\ttemp = (temp >>> 1);\n\t\t\t\t}\n\t\t\t}\n\t\t\tcrc = (crc >>> 8) ^ temp;\n\t\t}\n\n\t\t// flip bits\n\t\treturn crc ^ -1;\n\t}\n\n\t/*\n\t * Compute CRC with the help of a pre-calculated table.\n\t *\n\t * This supports append mode, if the second parameter is set.\n\t */\n\tfunction crcTable(arr, append) {\n\t\tvar crc, i, l;\n\n\t\t// if we're in append mode, don't reset crc\n\t\t// if arr is null or undefined, reset table and return\n\t\tif (typeof crcTable.crc === 'undefined' || !append || !arr) {\n\t\t\tcrcTable.crc = 0 ^ -1;\n\n\t\t\tif (!arr) {\n\t\t\t\treturn;\n\t\t\t}\n\t\t}\n\n\t\t// store in temp variable for minor speed gain\n\t\tcrc = crcTable.crc;\n\n\t\tfor (i = 0, l = arr.length; i < l; i += 1) {\n\t\t\tcrc = (crc >>> 8) ^ table[(crc ^ arr[i]) & 0xff];\n\t\t}\n\n\t\tcrcTable.crc = crc;\n\n\t\treturn crc ^ -1;\n\t}\n\n\t// build the table\n\t// this isn't that costly, and most uses will be for table assisted mode\n\tmakeTable();\n\n\tmodule.exports = function (val, direct) {\n\t\tvar val = (typeof val === 'string') ? strToArr(val) : val,\n\t\t\tret = direct ? crcDirect(val) : crcTable(val);\n\n\t\t// convert to 2's complement hex\n\t\treturn (ret >>> 0).toString(16);\n\t};\n\tmodule.exports.direct = crcDirect;\n\tmodule.exports.table = crcTable;\n}());\n\n\n//////////////////\n// WEBPACK FOOTER\n// ../node_modules/crc32/lib/crc32.js\n// module id = 3\n// module chunks = 0\n\n//# sourceURL=webpack:///../node_modules/crc32/lib/crc32.js?");

/***/ }),
/* 4 */
/***/ (function(module, exports, __webpack_require__) {

eval("(function () {\n\t'use strict';\n\n\tmodule.exports = {\n\t\t'inflate': __webpack_require__(5),\n\t\t'deflate': __webpack_require__(6)\n\t};\n}());\n\n\n//////////////////\n// WEBPACK FOOTER\n// ../node_modules/deflate-js/index.js\n// module id = 4\n// module chunks = 0\n\n//# sourceURL=webpack:///../node_modules/deflate-js/index.js?");

/***/ }),
/* 5 */
/***/ (function(module, exports) {

eval("/*\n * $Id: rawinflate.js,v 0.2 2009/03/01 18:32:24 dankogai Exp $\n *\n * original:\n * http://www.onicos.com/staff/iz/amuse/javascript/expert/inflate.txt\n */\n\n/* Copyright (C) 1999 Masanao Izumo <iz@onicos.co.jp>\n * Version: 1.0.0.1\n * LastModified: Dec 25 1999\n */\n\n/* Interface:\n * data = inflate(src);\n */\n\n(function () {\n\t/* constant parameters */\n\tvar WSIZE = 32768, // Sliding Window size\n\t\tSTORED_BLOCK = 0,\n\t\tSTATIC_TREES = 1,\n\t\tDYN_TREES = 2,\n\n\t/* for inflate */\n\t\tlbits = 9, // bits in base literal/length lookup table\n\t\tdbits = 6, // bits in base distance lookup table\n\n\t/* variables (inflate) */\n\t\tslide,\n\t\twp, // current position in slide\n\t\tfixed_tl = null, // inflate static\n\t\tfixed_td, // inflate static\n\t\tfixed_bl, // inflate static\n\t\tfixed_bd, // inflate static\n\t\tbit_buf, // bit buffer\n\t\tbit_len, // bits in bit buffer\n\t\tmethod,\n\t\teof,\n\t\tcopy_leng,\n\t\tcopy_dist,\n\t\ttl, // literal length decoder table\n\t\ttd, // literal distance decoder table\n\t\tbl, // number of bits decoded by tl\n\t\tbd, // number of bits decoded by td\n\n\t\tinflate_data,\n\t\tinflate_pos,\n\n\n/* constant tables (inflate) */\n\t\tMASK_BITS = [\n\t\t\t0x0000,\n\t\t\t0x0001, 0x0003, 0x0007, 0x000f, 0x001f, 0x003f, 0x007f, 0x00ff,\n\t\t\t0x01ff, 0x03ff, 0x07ff, 0x0fff, 0x1fff, 0x3fff, 0x7fff, 0xffff\n\t\t],\n\t\t// Tables for deflate from PKZIP's appnote.txt.\n\t\t// Copy lengths for literal codes 257..285\n\t\tcplens = [\n\t\t\t3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 15, 17, 19, 23, 27, 31,\n\t\t\t35, 43, 51, 59, 67, 83, 99, 115, 131, 163, 195, 227, 258, 0, 0\n\t\t],\n/* note: see note #13 above about the 258 in this list. */\n\t\t// Extra bits for literal codes 257..285\n\t\tcplext = [\n\t\t\t0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2,\n\t\t\t3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 0, 99, 99 // 99==invalid\n\t\t],\n\t\t// Copy offsets for distance codes 0..29\n\t\tcpdist = [\n\t\t\t1, 2, 3, 4, 5, 7, 9, 13, 17, 25, 33, 49, 65, 97, 129, 193,\n\t\t\t257, 385, 513, 769, 1025, 1537, 2049, 3073, 4097, 6145,\n\t\t\t8193, 12289, 16385, 24577\n\t\t],\n\t\t// Extra bits for distance codes\n\t\tcpdext = [\n\t\t\t0, 0, 0, 0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6,\n\t\t\t7, 7, 8, 8, 9, 9, 10, 10, 11, 11,\n\t\t\t12, 12, 13, 13\n\t\t],\n\t\t// Order of the bit length code lengths\n\t\tborder = [\n\t\t\t16, 17, 18, 0, 8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15\n\t\t];\n\t/* objects (inflate) */\n\n\tfunction HuftList() {\n\t\tthis.next = null;\n\t\tthis.list = null;\n\t}\n\n\tfunction HuftNode() {\n\t\tthis.e = 0; // number of extra bits or operation\n\t\tthis.b = 0; // number of bits in this code or subcode\n\n\t\t// union\n\t\tthis.n = 0; // literal, length base, or distance base\n\t\tthis.t = null; // (HuftNode) pointer to next level of table\n\t}\n\n\t/*\n\t * @param b-  code lengths in bits (all assumed <= BMAX)\n\t * @param n- number of codes (assumed <= N_MAX)\n\t * @param s- number of simple-valued codes (0..s-1)\n\t * @param d- list of base values for non-simple codes\n\t * @param e- list of extra bits for non-simple codes\n\t * @param mm- maximum lookup bits\n\t */\n\tfunction HuftBuild(b, n, s, d, e, mm) {\n\t\tthis.BMAX = 16; // maximum bit length of any code\n\t\tthis.N_MAX = 288; // maximum number of codes in any set\n\t\tthis.status = 0; // 0: success, 1: incomplete table, 2: bad input\n\t\tthis.root = null; // (HuftList) starting table\n\t\tthis.m = 0; // maximum lookup bits, returns actual\n\n\t/* Given a list of code lengths and a maximum table size, make a set of\n\t   tables to decode that set of codes. Return zero on success, one if\n\t   the given code set is incomplete (the tables are still built in this\n\t   case), two if the input is invalid (all zero length codes or an\n\t   oversubscribed set of lengths), and three if not enough memory.\n\t   The code with value 256 is special, and the tables are constructed\n\t   so that no bits beyond that code are fetched when that code is\n\t   decoded. */\n\t\tvar a; // counter for codes of length k\n\t\tvar c = [];\n\t\tvar el; // length of EOB code (value 256)\n\t\tvar f; // i repeats in table every f entries\n\t\tvar g; // maximum code length\n\t\tvar h; // table level\n\t\tvar i; // counter, current code\n\t\tvar j; // counter\n\t\tvar k; // number of bits in current code\n\t\tvar lx = [];\n\t\tvar p; // pointer into c[], b[], or v[]\n\t\tvar pidx; // index of p\n\t\tvar q; // (HuftNode) points to current table\n\t\tvar r = new HuftNode(); // table entry for structure assignment\n\t\tvar u = [];\n\t\tvar v = [];\n\t\tvar w;\n\t\tvar x = [];\n\t\tvar xp; // pointer into x or c\n\t\tvar y; // number of dummy codes added\n\t\tvar z; // number of entries in current table\n\t\tvar o;\n\t\tvar tail; // (HuftList)\n\n\t\ttail = this.root = null;\n\n\t\t// bit length count table\n\t\tfor (i = 0; i < this.BMAX + 1; i++) {\n\t\t\tc[i] = 0;\n\t\t}\n\t\t// stack of bits per table\n\t\tfor (i = 0; i < this.BMAX + 1; i++) {\n\t\t\tlx[i] = 0;\n\t\t}\n\t\t// HuftNode[BMAX][]  table stack\n\t\tfor (i = 0; i < this.BMAX; i++) {\n\t\t\tu[i] = null;\n\t\t}\n\t\t// values in order of bit length\n\t\tfor (i = 0; i < this.N_MAX; i++) {\n\t\t\tv[i] = 0;\n\t\t}\n\t\t// bit offsets, then code stack\n\t\tfor (i = 0; i < this.BMAX + 1; i++) {\n\t\t\tx[i] = 0;\n\t\t}\n\n\t\t// Generate counts for each bit length\n\t\tel = n > 256 ? b[256] : this.BMAX; // set length of EOB code, if any\n\t\tp = b; pidx = 0;\n\t\ti = n;\n\t\tdo {\n\t\t\tc[p[pidx]]++; // assume all entries <= BMAX\n\t\t\tpidx++;\n\t\t} while (--i > 0);\n\t\tif (c[0] === n) { // null input--all zero length codes\n\t\t\tthis.root = null;\n\t\t\tthis.m = 0;\n\t\t\tthis.status = 0;\n\t\t\treturn;\n\t\t}\n\n\t\t// Find minimum and maximum length, bound *m by those\n\t\tfor (j = 1; j <= this.BMAX; j++) {\n\t\t\tif (c[j] !== 0) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tk = j; // minimum code length\n\t\tif (mm < j) {\n\t\t\tmm = j;\n\t\t}\n\t\tfor (i = this.BMAX; i !== 0; i--) {\n\t\t\tif (c[i] !== 0) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tg = i; // maximum code length\n\t\tif (mm > i) {\n\t\t\tmm = i;\n\t\t}\n\n\t\t// Adjust last length count to fill out codes, if needed\n\t\tfor (y = 1 << j; j < i; j++, y <<= 1) {\n\t\t\tif ((y -= c[j]) < 0) {\n\t\t\t\tthis.status = 2; // bad input: more codes than bits\n\t\t\t\tthis.m = mm;\n\t\t\t\treturn;\n\t\t\t}\n\t\t}\n\t\tif ((y -= c[i]) < 0) {\n\t\t\tthis.status = 2;\n\t\t\tthis.m = mm;\n\t\t\treturn;\n\t\t}\n\t\tc[i] += y;\n\n\t\t// Generate starting offsets into the value table for each length\n\t\tx[1] = j = 0;\n\t\tp = c;\n\t\tpidx = 1;\n\t\txp = 2;\n\t\twhile (--i > 0) { // note that i == g from above\n\t\t\tx[xp++] = (j += p[pidx++]);\n\t\t}\n\n\t\t// Make a table of values in order of bit lengths\n\t\tp = b; pidx = 0;\n\t\ti = 0;\n\t\tdo {\n\t\t\tif ((j = p[pidx++]) !== 0) {\n\t\t\t\tv[x[j]++] = i;\n\t\t\t}\n\t\t} while (++i < n);\n\t\tn = x[g]; // set n to length of v\n\n\t\t// Generate the Huffman codes and for each, make the table entries\n\t\tx[0] = i = 0; // first Huffman code is zero\n\t\tp = v; pidx = 0; // grab values in bit order\n\t\th = -1; // no tables yet--level -1\n\t\tw = lx[0] = 0; // no bits decoded yet\n\t\tq = null; // ditto\n\t\tz = 0; // ditto\n\n\t\t// go through the bit lengths (k already is bits in shortest code)\n\t\tfor (null; k <= g; k++) {\n\t\t\ta = c[k];\n\t\t\twhile (a-- > 0) {\n\t\t\t\t// here i is the Huffman code of length k bits for value p[pidx]\n\t\t\t\t// make tables up to required level\n\t\t\t\twhile (k > w + lx[1 + h]) {\n\t\t\t\t\tw += lx[1 + h]; // add bits already decoded\n\t\t\t\t\th++;\n\n\t\t\t\t\t// compute minimum size table less than or equal to *m bits\n\t\t\t\t\tz = (z = g - w) > mm ? mm : z; // upper limit\n\t\t\t\t\tif ((f = 1 << (j = k - w)) > a + 1) { // try a k-w bit table\n\t\t\t\t\t\t// too few codes for k-w bit table\n\t\t\t\t\t\tf -= a + 1; // deduct codes from patterns left\n\t\t\t\t\t\txp = k;\n\t\t\t\t\t\twhile (++j < z) { // try smaller tables up to z bits\n\t\t\t\t\t\t\tif ((f <<= 1) <= c[++xp]) {\n\t\t\t\t\t\t\t\tbreak; // enough codes to use up j bits\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tf -= c[xp]; // else deduct codes from patterns\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif (w + j > el && w < el) {\n\t\t\t\t\t\tj = el - w; // make EOB code end at table\n\t\t\t\t\t}\n\t\t\t\t\tz = 1 << j; // table entries for j-bit table\n\t\t\t\t\tlx[1 + h] = j; // set table size in stack\n\n\t\t\t\t\t// allocate and link in new table\n\t\t\t\t\tq = [];\n\t\t\t\t\tfor (o = 0; o < z; o++) {\n\t\t\t\t\t\tq[o] = new HuftNode();\n\t\t\t\t\t}\n\n\t\t\t\t\tif (!tail) {\n\t\t\t\t\t\ttail = this.root = new HuftList();\n\t\t\t\t\t} else {\n\t\t\t\t\t\ttail = tail.next = new HuftList();\n\t\t\t\t\t}\n\t\t\t\t\ttail.next = null;\n\t\t\t\t\ttail.list = q;\n\t\t\t\t\tu[h] = q; // table starts after link\n\n\t\t\t\t\t/* connect to last table, if there is one */\n\t\t\t\t\tif (h > 0) {\n\t\t\t\t\t\tx[h] = i; // save pattern for backing up\n\t\t\t\t\t\tr.b = lx[h]; // bits to dump before this table\n\t\t\t\t\t\tr.e = 16 + j; // bits in this table\n\t\t\t\t\t\tr.t = q; // pointer to this table\n\t\t\t\t\t\tj = (i & ((1 << w) - 1)) >> (w - lx[h]);\n\t\t\t\t\t\tu[h - 1][j].e = r.e;\n\t\t\t\t\t\tu[h - 1][j].b = r.b;\n\t\t\t\t\t\tu[h - 1][j].n = r.n;\n\t\t\t\t\t\tu[h - 1][j].t = r.t;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// set up table entry in r\n\t\t\t\tr.b = k - w;\n\t\t\t\tif (pidx >= n) {\n\t\t\t\t\tr.e = 99; // out of values--invalid code\n\t\t\t\t} else if (p[pidx] < s) {\n\t\t\t\t\tr.e = (p[pidx] < 256 ? 16 : 15); // 256 is end-of-block code\n\t\t\t\t\tr.n = p[pidx++]; // simple code is just the value\n\t\t\t\t} else {\n\t\t\t\t\tr.e = e[p[pidx] - s]; // non-simple--look up in lists\n\t\t\t\t\tr.n = d[p[pidx++] - s];\n\t\t\t\t}\n\n\t\t\t\t// fill code-like entries with r //\n\t\t\t\tf = 1 << (k - w);\n\t\t\t\tfor (j = i >> w; j < z; j += f) {\n\t\t\t\t\tq[j].e = r.e;\n\t\t\t\t\tq[j].b = r.b;\n\t\t\t\t\tq[j].n = r.n;\n\t\t\t\t\tq[j].t = r.t;\n\t\t\t\t}\n\n\t\t\t\t// backwards increment the k-bit code i\n\t\t\t\tfor (j = 1 << (k - 1); (i & j) !== 0; j >>= 1) {\n\t\t\t\t\ti ^= j;\n\t\t\t\t}\n\t\t\t\ti ^= j;\n\n\t\t\t\t// backup over finished tables\n\t\t\t\twhile ((i & ((1 << w) - 1)) !== x[h]) {\n\t\t\t\t\tw -= lx[h]; // don't need to update q\n\t\t\t\t\th--;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t/* return actual size of base table */\n\t\tthis.m = lx[1];\n\n\t\t/* Return true (1) if we were given an incomplete table */\n\t\tthis.status = ((y !== 0 && g !== 1) ? 1 : 0);\n\t}\n\n\n\t/* routines (inflate) */\n\n\tfunction GET_BYTE() {\n\t\tif (inflate_data.length === inflate_pos) {\n\t\t\treturn -1;\n\t\t}\n\t\treturn inflate_data[inflate_pos++] & 0xff;\n\t}\n\n\tfunction NEEDBITS(n) {\n\t\twhile (bit_len < n) {\n\t\t\tbit_buf |= GET_BYTE() << bit_len;\n\t\t\tbit_len += 8;\n\t\t}\n\t}\n\n\tfunction GETBITS(n) {\n\t\treturn bit_buf & MASK_BITS[n];\n\t}\n\n\tfunction DUMPBITS(n) {\n\t\tbit_buf >>= n;\n\t\tbit_len -= n;\n\t}\n\n\tfunction inflate_codes(buff, off, size) {\n\t\t// inflate (decompress) the codes in a deflated (compressed) block.\n\t\t// Return an error code or zero if it all goes ok.\n\t\tvar e; // table entry flag/number of extra bits\n\t\tvar t; // (HuftNode) pointer to table entry\n\t\tvar n;\n\n\t\tif (size === 0) {\n\t\t\treturn 0;\n\t\t}\n\n\t\t// inflate the coded data\n\t\tn = 0;\n\t\tfor (;;) { // do until end of block\n\t\t\tNEEDBITS(bl);\n\t\t\tt = tl.list[GETBITS(bl)];\n\t\t\te = t.e;\n\t\t\twhile (e > 16) {\n\t\t\t\tif (e === 99) {\n\t\t\t\t\treturn -1;\n\t\t\t\t}\n\t\t\t\tDUMPBITS(t.b);\n\t\t\t\te -= 16;\n\t\t\t\tNEEDBITS(e);\n\t\t\t\tt = t.t[GETBITS(e)];\n\t\t\t\te = t.e;\n\t\t\t}\n\t\t\tDUMPBITS(t.b);\n\n\t\t\tif (e === 16) { // then it's a literal\n\t\t\t\twp &= WSIZE - 1;\n\t\t\t\tbuff[off + n++] = slide[wp++] = t.n;\n\t\t\t\tif (n === size) {\n\t\t\t\t\treturn size;\n\t\t\t\t}\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\t// exit if end of block\n\t\t\tif (e === 15) {\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t// it's an EOB or a length\n\n\t\t\t// get length of block to copy\n\t\t\tNEEDBITS(e);\n\t\t\tcopy_leng = t.n + GETBITS(e);\n\t\t\tDUMPBITS(e);\n\n\t\t\t// decode distance of block to copy\n\t\t\tNEEDBITS(bd);\n\t\t\tt = td.list[GETBITS(bd)];\n\t\t\te = t.e;\n\n\t\t\twhile (e > 16) {\n\t\t\t\tif (e === 99) {\n\t\t\t\t\treturn -1;\n\t\t\t\t}\n\t\t\t\tDUMPBITS(t.b);\n\t\t\t\te -= 16;\n\t\t\t\tNEEDBITS(e);\n\t\t\t\tt = t.t[GETBITS(e)];\n\t\t\t\te = t.e;\n\t\t\t}\n\t\t\tDUMPBITS(t.b);\n\t\t\tNEEDBITS(e);\n\t\t\tcopy_dist = wp - t.n - GETBITS(e);\n\t\t\tDUMPBITS(e);\n\n\t\t\t// do the copy\n\t\t\twhile (copy_leng > 0 && n < size) {\n\t\t\t\tcopy_leng--;\n\t\t\t\tcopy_dist &= WSIZE - 1;\n\t\t\t\twp &= WSIZE - 1;\n\t\t\t\tbuff[off + n++] = slide[wp++] = slide[copy_dist++];\n\t\t\t}\n\n\t\t\tif (n === size) {\n\t\t\t\treturn size;\n\t\t\t}\n\t\t}\n\n\t\tmethod = -1; // done\n\t\treturn n;\n\t}\n\n\tfunction inflate_stored(buff, off, size) {\n\t\t/* \"decompress\" an inflated type 0 (stored) block. */\n\t\tvar n;\n\n\t\t// go to byte boundary\n\t\tn = bit_len & 7;\n\t\tDUMPBITS(n);\n\n\t\t// get the length and its complement\n\t\tNEEDBITS(16);\n\t\tn = GETBITS(16);\n\t\tDUMPBITS(16);\n\t\tNEEDBITS(16);\n\t\tif (n !== ((~bit_buf) & 0xffff)) {\n\t\t\treturn -1; // error in compressed data\n\t\t}\n\t\tDUMPBITS(16);\n\n\t\t// read and output the compressed data\n\t\tcopy_leng = n;\n\n\t\tn = 0;\n\t\twhile (copy_leng > 0 && n < size) {\n\t\t\tcopy_leng--;\n\t\t\twp &= WSIZE - 1;\n\t\t\tNEEDBITS(8);\n\t\t\tbuff[off + n++] = slide[wp++] = GETBITS(8);\n\t\t\tDUMPBITS(8);\n\t\t}\n\n\t\tif (copy_leng === 0) {\n\t\t\tmethod = -1; // done\n\t\t}\n\t\treturn n;\n\t}\n\n\tfunction inflate_fixed(buff, off, size) {\n\t\t// decompress an inflated type 1 (fixed Huffman codes) block.  We should\n\t\t// either replace this with a custom decoder, or at least precompute the\n\t\t// Huffman tables.\n\n\t\t// if first time, set up tables for fixed blocks\n\t\tif (!fixed_tl) {\n\t\t\tvar i; // temporary variable\n\t\t\tvar l = []; // 288 length list for huft_build (initialized below)\n\t\t\tvar h; // HuftBuild\n\n\t\t\t// literal table\n\t\t\tfor (i = 0; i < 144; i++) {\n\t\t\t\tl[i] = 8;\n\t\t\t}\n\t\t\tfor (null; i < 256; i++) {\n\t\t\t\tl[i] = 9;\n\t\t\t}\n\t\t\tfor (null; i < 280; i++) {\n\t\t\t\tl[i] = 7;\n\t\t\t}\n\t\t\tfor (null; i < 288; i++) { // make a complete, but wrong code set\n\t\t\t\tl[i] = 8;\n\t\t\t}\n\t\t\tfixed_bl = 7;\n\n\t\t\th = new HuftBuild(l, 288, 257, cplens, cplext, fixed_bl);\n\t\t\tif (h.status !== 0) {\n\t\t\t\tconsole.error(\"HufBuild error: \" + h.status);\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tfixed_tl = h.root;\n\t\t\tfixed_bl = h.m;\n\n\t\t\t// distance table\n\t\t\tfor (i = 0; i < 30; i++) { // make an incomplete code set\n\t\t\t\tl[i] = 5;\n\t\t\t}\n\t\t\tfixed_bd = 5;\n\n\t\t\th = new HuftBuild(l, 30, 0, cpdist, cpdext, fixed_bd);\n\t\t\tif (h.status > 1) {\n\t\t\t\tfixed_tl = null;\n\t\t\t\tconsole.error(\"HufBuild error: \" + h.status);\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tfixed_td = h.root;\n\t\t\tfixed_bd = h.m;\n\t\t}\n\n\t\ttl = fixed_tl;\n\t\ttd = fixed_td;\n\t\tbl = fixed_bl;\n\t\tbd = fixed_bd;\n\t\treturn inflate_codes(buff, off, size);\n\t}\n\n\tfunction inflate_dynamic(buff, off, size) {\n\t\t// decompress an inflated type 2 (dynamic Huffman codes) block.\n\t\tvar i; // temporary variables\n\t\tvar j;\n\t\tvar l; // last length\n\t\tvar n; // number of lengths to get\n\t\tvar t; // (HuftNode) literal/length code table\n\t\tvar nb; // number of bit length codes\n\t\tvar nl; // number of literal/length codes\n\t\tvar nd; // number of distance codes\n\t\tvar ll = [];\n\t\tvar h; // (HuftBuild)\n\n\t\t// literal/length and distance code lengths\n\t\tfor (i = 0; i < 286 + 30; i++) {\n\t\t\tll[i] = 0;\n\t\t}\n\n\t\t// read in table lengths\n\t\tNEEDBITS(5);\n\t\tnl = 257 + GETBITS(5); // number of literal/length codes\n\t\tDUMPBITS(5);\n\t\tNEEDBITS(5);\n\t\tnd = 1 + GETBITS(5); // number of distance codes\n\t\tDUMPBITS(5);\n\t\tNEEDBITS(4);\n\t\tnb = 4 + GETBITS(4); // number of bit length codes\n\t\tDUMPBITS(4);\n\t\tif (nl > 286 || nd > 30) {\n\t\t\treturn -1; // bad lengths\n\t\t}\n\n\t\t// read in bit-length-code lengths\n\t\tfor (j = 0; j < nb; j++) {\n\t\t\tNEEDBITS(3);\n\t\t\tll[border[j]] = GETBITS(3);\n\t\t\tDUMPBITS(3);\n\t\t}\n\t\tfor (null; j < 19; j++) {\n\t\t\tll[border[j]] = 0;\n\t\t}\n\n\t\t// build decoding table for trees--single level, 7 bit lookup\n\t\tbl = 7;\n\t\th = new HuftBuild(ll, 19, 19, null, null, bl);\n\t\tif (h.status !== 0) {\n\t\t\treturn -1; // incomplete code set\n\t\t}\n\n\t\ttl = h.root;\n\t\tbl = h.m;\n\n\t\t// read in literal and distance code lengths\n\t\tn = nl + nd;\n\t\ti = l = 0;\n\t\twhile (i < n) {\n\t\t\tNEEDBITS(bl);\n\t\t\tt = tl.list[GETBITS(bl)];\n\t\t\tj = t.b;\n\t\t\tDUMPBITS(j);\n\t\t\tj = t.n;\n\t\t\tif (j < 16) { // length of code in bits (0..15)\n\t\t\t\tll[i++] = l = j; // save last length in l\n\t\t\t} else if (j === 16) { // repeat last length 3 to 6 times\n\t\t\t\tNEEDBITS(2);\n\t\t\t\tj = 3 + GETBITS(2);\n\t\t\t\tDUMPBITS(2);\n\t\t\t\tif (i + j > n) {\n\t\t\t\t\treturn -1;\n\t\t\t\t}\n\t\t\t\twhile (j-- > 0) {\n\t\t\t\t\tll[i++] = l;\n\t\t\t\t}\n\t\t\t} else if (j === 17) { // 3 to 10 zero length codes\n\t\t\t\tNEEDBITS(3);\n\t\t\t\tj = 3 + GETBITS(3);\n\t\t\t\tDUMPBITS(3);\n\t\t\t\tif (i + j > n) {\n\t\t\t\t\treturn -1;\n\t\t\t\t}\n\t\t\t\twhile (j-- > 0) {\n\t\t\t\t\tll[i++] = 0;\n\t\t\t\t}\n\t\t\t\tl = 0;\n\t\t\t} else { // j === 18: 11 to 138 zero length codes\n\t\t\t\tNEEDBITS(7);\n\t\t\t\tj = 11 + GETBITS(7);\n\t\t\t\tDUMPBITS(7);\n\t\t\t\tif (i + j > n) {\n\t\t\t\t\treturn -1;\n\t\t\t\t}\n\t\t\t\twhile (j-- > 0) {\n\t\t\t\t\tll[i++] = 0;\n\t\t\t\t}\n\t\t\t\tl = 0;\n\t\t\t}\n\t\t}\n\n\t\t// build the decoding tables for literal/length and distance codes\n\t\tbl = lbits;\n\t\th = new HuftBuild(ll, nl, 257, cplens, cplext, bl);\n\t\tif (bl === 0) { // no literals or lengths\n\t\t\th.status = 1;\n\t\t}\n\t\tif (h.status !== 0) {\n\t\t\tif (h.status !== 1) {\n\t\t\t\treturn -1; // incomplete code set\n\t\t\t}\n\t\t\t// **incomplete literal tree**\n\t\t}\n\t\ttl = h.root;\n\t\tbl = h.m;\n\n\t\tfor (i = 0; i < nd; i++) {\n\t\t\tll[i] = ll[i + nl];\n\t\t}\n\t\tbd = dbits;\n\t\th = new HuftBuild(ll, nd, 0, cpdist, cpdext, bd);\n\t\ttd = h.root;\n\t\tbd = h.m;\n\n\t\tif (bd === 0 && nl > 257) { // lengths but no distances\n\t\t\t// **incomplete distance tree**\n\t\t\treturn -1;\n\t\t}\n/*\n\t\tif (h.status === 1) {\n\t\t\t// **incomplete distance tree**\n\t\t}\n*/\n\t\tif (h.status !== 0) {\n\t\t\treturn -1;\n\t\t}\n\n\t\t// decompress until an end-of-block code\n\t\treturn inflate_codes(buff, off, size);\n\t}\n\n\tfunction inflate_start() {\n\t\tif (!slide) {\n\t\t\tslide = []; // new Array(2 * WSIZE); // slide.length is never called\n\t\t}\n\t\twp = 0;\n\t\tbit_buf = 0;\n\t\tbit_len = 0;\n\t\tmethod = -1;\n\t\teof = false;\n\t\tcopy_leng = copy_dist = 0;\n\t\ttl = null;\n\t}\n\n\tfunction inflate_internal(buff, off, size) {\n\t\t// decompress an inflated entry\n\t\tvar n, i;\n\n\t\tn = 0;\n\t\twhile (n < size) {\n\t\t\tif (eof && method === -1) {\n\t\t\t\treturn n;\n\t\t\t}\n\n\t\t\tif (copy_leng > 0) {\n\t\t\t\tif (method !== STORED_BLOCK) {\n\t\t\t\t\t// STATIC_TREES or DYN_TREES\n\t\t\t\t\twhile (copy_leng > 0 && n < size) {\n\t\t\t\t\t\tcopy_leng--;\n\t\t\t\t\t\tcopy_dist &= WSIZE - 1;\n\t\t\t\t\t\twp &= WSIZE - 1;\n\t\t\t\t\t\tbuff[off + n++] = slide[wp++] = slide[copy_dist++];\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\twhile (copy_leng > 0 && n < size) {\n\t\t\t\t\t\tcopy_leng--;\n\t\t\t\t\t\twp &= WSIZE - 1;\n\t\t\t\t\t\tNEEDBITS(8);\n\t\t\t\t\t\tbuff[off + n++] = slide[wp++] = GETBITS(8);\n\t\t\t\t\t\tDUMPBITS(8);\n\t\t\t\t\t}\n\t\t\t\t\tif (copy_leng === 0) {\n\t\t\t\t\t\tmethod = -1; // done\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (n === size) {\n\t\t\t\t\treturn n;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (method === -1) {\n\t\t\t\tif (eof) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\n\t\t\t\t// read in last block bit\n\t\t\t\tNEEDBITS(1);\n\t\t\t\tif (GETBITS(1) !== 0) {\n\t\t\t\t\teof = true;\n\t\t\t\t}\n\t\t\t\tDUMPBITS(1);\n\n\t\t\t\t// read in block type\n\t\t\t\tNEEDBITS(2);\n\t\t\t\tmethod = GETBITS(2);\n\t\t\t\tDUMPBITS(2);\n\t\t\t\ttl = null;\n\t\t\t\tcopy_leng = 0;\n\t\t\t}\n\n\t\t\tswitch (method) {\n\t\t\tcase STORED_BLOCK:\n\t\t\t\ti = inflate_stored(buff, off + n, size - n);\n\t\t\t\tbreak;\n\n\t\t\tcase STATIC_TREES:\n\t\t\t\tif (tl) {\n\t\t\t\t\ti = inflate_codes(buff, off + n, size - n);\n\t\t\t\t} else {\n\t\t\t\t\ti = inflate_fixed(buff, off + n, size - n);\n\t\t\t\t}\n\t\t\t\tbreak;\n\n\t\t\tcase DYN_TREES:\n\t\t\t\tif (tl) {\n\t\t\t\t\ti = inflate_codes(buff, off + n, size - n);\n\t\t\t\t} else {\n\t\t\t\t\ti = inflate_dynamic(buff, off + n, size - n);\n\t\t\t\t}\n\t\t\t\tbreak;\n\n\t\t\tdefault: // error\n\t\t\t\ti = -1;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tif (i === -1) {\n\t\t\t\tif (eof) {\n\t\t\t\t\treturn 0;\n\t\t\t\t}\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tn += i;\n\t\t}\n\t\treturn n;\n\t}\n\n\tfunction inflate(arr) {\n\t\tvar buff = [], i;\n\n\t\tinflate_start();\n\t\tinflate_data = arr;\n\t\tinflate_pos = 0;\n\n\t\tdo {\n\t\t\ti = inflate_internal(buff, buff.length, 1024);\n\t\t} while (i > 0);\n\t\tinflate_data = null; // G.C.\n\t\treturn buff;\n\t}\n\n\tmodule.exports = inflate;\n}());\n\n\n//////////////////\n// WEBPACK FOOTER\n// ../node_modules/deflate-js/lib/rawinflate.js\n// module id = 5\n// module chunks = 0\n\n//# sourceURL=webpack:///../node_modules/deflate-js/lib/rawinflate.js?");

/***/ }),
/* 6 */
/***/ (function(module, exports) {

eval("/*\n * $Id: rawdeflate.js,v 0.3 2009/03/01 19:05:05 dankogai Exp dankogai $\n *\n * Original:\n *   http://www.onicos.com/staff/iz/amuse/javascript/expert/deflate.txt\n */\n\n/* Copyright (C) 1999 Masanao Izumo <iz@onicos.co.jp>\n * Version: 1.0.1\n * LastModified: Dec 25 1999\n */\n\n/* Interface:\n * data = deflate(src);\n */\n\n(function () {\n\t/* constant parameters */\n\tvar WSIZE = 32768, // Sliding Window size\n\t\tSTORED_BLOCK = 0,\n\t\tSTATIC_TREES = 1,\n\t\tDYN_TREES = 2,\n\n\t/* for deflate */\n\t\tDEFAULT_LEVEL = 6,\n\t\tFULL_SEARCH = false,\n\t\tINBUFSIZ = 32768, // Input buffer size\n\t\t//INBUF_EXTRA = 64, // Extra buffer\n\t\tOUTBUFSIZ = 1024 * 8,\n\t\twindow_size = 2 * WSIZE,\n\t\tMIN_MATCH = 3,\n\t\tMAX_MATCH = 258,\n\t\tBITS = 16,\n\t// for SMALL_MEM\n\t\tLIT_BUFSIZE = 0x2000,\n//\t\tHASH_BITS = 13,\n\t//for MEDIUM_MEM\n\t//\tLIT_BUFSIZE = 0x4000,\n\t//\tHASH_BITS = 14,\n\t// for BIG_MEM\n\t//\tLIT_BUFSIZE = 0x8000,\n\t\tHASH_BITS = 15,\n\t\tDIST_BUFSIZE = LIT_BUFSIZE,\n\t\tHASH_SIZE = 1 << HASH_BITS,\n\t\tHASH_MASK = HASH_SIZE - 1,\n\t\tWMASK = WSIZE - 1,\n\t\tNIL = 0, // Tail of hash chains\n\t\tTOO_FAR = 4096,\n\t\tMIN_LOOKAHEAD = MAX_MATCH + MIN_MATCH + 1,\n\t\tMAX_DIST = WSIZE - MIN_LOOKAHEAD,\n\t\tSMALLEST = 1,\n\t\tMAX_BITS = 15,\n\t\tMAX_BL_BITS = 7,\n\t\tLENGTH_CODES = 29,\n\t\tLITERALS = 256,\n\t\tEND_BLOCK = 256,\n\t\tL_CODES = LITERALS + 1 + LENGTH_CODES,\n\t\tD_CODES = 30,\n\t\tBL_CODES = 19,\n\t\tREP_3_6 = 16,\n\t\tREPZ_3_10 = 17,\n\t\tREPZ_11_138 = 18,\n\t\tHEAP_SIZE = 2 * L_CODES + 1,\n\t\tH_SHIFT = parseInt((HASH_BITS + MIN_MATCH - 1) / MIN_MATCH, 10),\n\n\t/* variables */\n\t\tfree_queue,\n\t\tqhead,\n\t\tqtail,\n\t\tinitflag,\n\t\toutbuf = null,\n\t\toutcnt,\n\t\toutoff,\n\t\tcomplete,\n\t\twindow,\n\t\td_buf,\n\t\tl_buf,\n\t\tprev,\n\t\tbi_buf,\n\t\tbi_valid,\n\t\tblock_start,\n\t\tins_h,\n\t\thash_head,\n\t\tprev_match,\n\t\tmatch_available,\n\t\tmatch_length,\n\t\tprev_length,\n\t\tstrstart,\n\t\tmatch_start,\n\t\teofile,\n\t\tlookahead,\n\t\tmax_chain_length,\n\t\tmax_lazy_match,\n\t\tcompr_level,\n\t\tgood_match,\n\t\tnice_match,\n\t\tdyn_ltree,\n\t\tdyn_dtree,\n\t\tstatic_ltree,\n\t\tstatic_dtree,\n\t\tbl_tree,\n\t\tl_desc,\n\t\td_desc,\n\t\tbl_desc,\n\t\tbl_count,\n\t\theap,\n\t\theap_len,\n\t\theap_max,\n\t\tdepth,\n\t\tlength_code,\n\t\tdist_code,\n\t\tbase_length,\n\t\tbase_dist,\n\t\tflag_buf,\n\t\tlast_lit,\n\t\tlast_dist,\n\t\tlast_flags,\n\t\tflags,\n\t\tflag_bit,\n\t\topt_len,\n\t\tstatic_len,\n\t\tdeflate_data,\n\t\tdeflate_pos;\n\n\tif (LIT_BUFSIZE > INBUFSIZ) {\n\t\tconsole.error(\"error: INBUFSIZ is too small\");\n\t}\n\tif ((WSIZE << 1) > (1 << BITS)) {\n\t\tconsole.error(\"error: WSIZE is too large\");\n\t}\n\tif (HASH_BITS > BITS - 1) {\n\t\tconsole.error(\"error: HASH_BITS is too large\");\n\t}\n\tif (HASH_BITS < 8 || MAX_MATCH !== 258) {\n\t\tconsole.error(\"error: Code too clever\");\n\t}\n\n\t/* objects (deflate) */\n\n\tfunction DeflateCT() {\n\t\tthis.fc = 0; // frequency count or bit string\n\t\tthis.dl = 0; // father node in Huffman tree or length of bit string\n\t}\n\n\tfunction DeflateTreeDesc() {\n\t\tthis.dyn_tree = null; // the dynamic tree\n\t\tthis.static_tree = null; // corresponding static tree or NULL\n\t\tthis.extra_bits = null; // extra bits for each code or NULL\n\t\tthis.extra_base = 0; // base index for extra_bits\n\t\tthis.elems = 0; // max number of elements in the tree\n\t\tthis.max_length = 0; // max bit length for the codes\n\t\tthis.max_code = 0; // largest code with non zero frequency\n\t}\n\n\t/* Values for max_lazy_match, good_match and max_chain_length, depending on\n\t * the desired pack level (0..9). The values given below have been tuned to\n\t * exclude worst case performance for pathological files. Better values may be\n\t * found for specific files.\n\t */\n\tfunction DeflateConfiguration(a, b, c, d) {\n\t\tthis.good_length = a; // reduce lazy search above this match length\n\t\tthis.max_lazy = b; // do not perform lazy search above this match length\n\t\tthis.nice_length = c; // quit search above this match length\n\t\tthis.max_chain = d;\n\t}\n\n\tfunction DeflateBuffer() {\n\t\tthis.next = null;\n\t\tthis.len = 0;\n\t\tthis.ptr = []; // new Array(OUTBUFSIZ); // ptr.length is never read\n\t\tthis.off = 0;\n\t}\n\n\t/* constant tables */\n\tvar extra_lbits = [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 0];\n\tvar extra_dbits = [0, 0, 0, 0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10, 10, 11, 11, 12, 12, 13, 13];\n\tvar extra_blbits = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 3, 7];\n\tvar bl_order = [16, 17, 18, 0, 8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15];\n\tvar configuration_table = [\n\t\tnew DeflateConfiguration(0, 0, 0, 0),\n\t\tnew DeflateConfiguration(4, 4, 8, 4),\n\t\tnew DeflateConfiguration(4, 5, 16, 8),\n\t\tnew DeflateConfiguration(4, 6, 32, 32),\n\t\tnew DeflateConfiguration(4, 4, 16, 16),\n\t\tnew DeflateConfiguration(8, 16, 32, 32),\n\t\tnew DeflateConfiguration(8, 16, 128, 128),\n\t\tnew DeflateConfiguration(8, 32, 128, 256),\n\t\tnew DeflateConfiguration(32, 128, 258, 1024),\n\t\tnew DeflateConfiguration(32, 258, 258, 4096)\n\t];\n\n\n\t/* routines (deflate) */\n\n\tfunction deflate_start(level) {\n\t\tvar i;\n\n\t\tif (!level) {\n\t\t\tlevel = DEFAULT_LEVEL;\n\t\t} else if (level < 1) {\n\t\t\tlevel = 1;\n\t\t} else if (level > 9) {\n\t\t\tlevel = 9;\n\t\t}\n\n\t\tcompr_level = level;\n\t\tinitflag = false;\n\t\teofile = false;\n\t\tif (outbuf !== null) {\n\t\t\treturn;\n\t\t}\n\n\t\tfree_queue = qhead = qtail = null;\n\t\toutbuf = []; // new Array(OUTBUFSIZ); // outbuf.length never called\n\t\twindow = []; // new Array(window_size); // window.length never called\n\t\td_buf = []; // new Array(DIST_BUFSIZE); // d_buf.length never called\n\t\tl_buf = []; // new Array(INBUFSIZ + INBUF_EXTRA); // l_buf.length never called\n\t\tprev = []; // new Array(1 << BITS); // prev.length never called\n\n\t\tdyn_ltree = [];\n\t\tfor (i = 0; i < HEAP_SIZE; i++) {\n\t\t\tdyn_ltree[i] = new DeflateCT();\n\t\t}\n\t\tdyn_dtree = [];\n\t\tfor (i = 0; i < 2 * D_CODES + 1; i++) {\n\t\t\tdyn_dtree[i] = new DeflateCT();\n\t\t}\n\t\tstatic_ltree = [];\n\t\tfor (i = 0; i < L_CODES + 2; i++) {\n\t\t\tstatic_ltree[i] = new DeflateCT();\n\t\t}\n\t\tstatic_dtree = [];\n\t\tfor (i = 0; i < D_CODES; i++) {\n\t\t\tstatic_dtree[i] = new DeflateCT();\n\t\t}\n\t\tbl_tree = [];\n\t\tfor (i = 0; i < 2 * BL_CODES + 1; i++) {\n\t\t\tbl_tree[i] = new DeflateCT();\n\t\t}\n\t\tl_desc = new DeflateTreeDesc();\n\t\td_desc = new DeflateTreeDesc();\n\t\tbl_desc = new DeflateTreeDesc();\n\t\tbl_count = []; // new Array(MAX_BITS+1); // bl_count.length never called\n\t\theap = []; // new Array(2*L_CODES+1); // heap.length never called\n\t\tdepth = []; // new Array(2*L_CODES+1); // depth.length never called\n\t\tlength_code = []; // new Array(MAX_MATCH-MIN_MATCH+1); // length_code.length never called\n\t\tdist_code = []; // new Array(512); // dist_code.length never called\n\t\tbase_length = []; // new Array(LENGTH_CODES); // base_length.length never called\n\t\tbase_dist = []; // new Array(D_CODES); // base_dist.length never called\n\t\tflag_buf = []; // new Array(parseInt(LIT_BUFSIZE / 8, 10)); // flag_buf.length never called\n\t}\n\n\tfunction deflate_end() {\n\t\tfree_queue = qhead = qtail = null;\n\t\toutbuf = null;\n\t\twindow = null;\n\t\td_buf = null;\n\t\tl_buf = null;\n\t\tprev = null;\n\t\tdyn_ltree = null;\n\t\tdyn_dtree = null;\n\t\tstatic_ltree = null;\n\t\tstatic_dtree = null;\n\t\tbl_tree = null;\n\t\tl_desc = null;\n\t\td_desc = null;\n\t\tbl_desc = null;\n\t\tbl_count = null;\n\t\theap = null;\n\t\tdepth = null;\n\t\tlength_code = null;\n\t\tdist_code = null;\n\t\tbase_length = null;\n\t\tbase_dist = null;\n\t\tflag_buf = null;\n\t}\n\n\tfunction reuse_queue(p) {\n\t\tp.next = free_queue;\n\t\tfree_queue = p;\n\t}\n\n\tfunction new_queue() {\n\t\tvar p;\n\n\t\tif (free_queue !== null) {\n\t\t\tp = free_queue;\n\t\t\tfree_queue = free_queue.next;\n\t\t} else {\n\t\t\tp = new DeflateBuffer();\n\t\t}\n\t\tp.next = null;\n\t\tp.len = p.off = 0;\n\n\t\treturn p;\n\t}\n\n\tfunction head1(i) {\n\t\treturn prev[WSIZE + i];\n\t}\n\n\tfunction head2(i, val) {\n\t\treturn (prev[WSIZE + i] = val);\n\t}\n\n\t/* put_byte is used for the compressed output, put_ubyte for the\n\t * uncompressed output. However unlzw() uses window for its\n\t * suffix table instead of its output buffer, so it does not use put_ubyte\n\t * (to be cleaned up).\n\t */\n\tfunction put_byte(c) {\n\t\toutbuf[outoff + outcnt++] = c;\n\t\tif (outoff + outcnt === OUTBUFSIZ) {\n\t\t\tqoutbuf();\n\t\t}\n\t}\n\n\t/* Output a 16 bit value, lsb first */\n\tfunction put_short(w) {\n\t\tw &= 0xffff;\n\t\tif (outoff + outcnt < OUTBUFSIZ - 2) {\n\t\t\toutbuf[outoff + outcnt++] = (w & 0xff);\n\t\t\toutbuf[outoff + outcnt++] = (w >>> 8);\n\t\t} else {\n\t\t\tput_byte(w & 0xff);\n\t\t\tput_byte(w >>> 8);\n\t\t}\n\t}\n\n\t/* ==========================================================================\n\t * Insert string s in the dictionary and set match_head to the previous head\n\t * of the hash chain (the most recent string with same hash key). Return\n\t * the previous length of the hash chain.\n\t * IN  assertion: all calls to to INSERT_STRING are made with consecutive\n\t *    input characters and the first MIN_MATCH bytes of s are valid\n\t *    (except for the last MIN_MATCH-1 bytes of the input file).\n\t */\n\tfunction INSERT_STRING() {\n\t\tins_h = ((ins_h << H_SHIFT) ^ (window[strstart + MIN_MATCH - 1] & 0xff)) & HASH_MASK;\n\t\thash_head = head1(ins_h);\n\t\tprev[strstart & WMASK] = hash_head;\n\t\thead2(ins_h, strstart);\n\t}\n\n\t/* Send a code of the given tree. c and tree must not have side effects */\n\tfunction SEND_CODE(c, tree) {\n\t\tsend_bits(tree[c].fc, tree[c].dl);\n\t}\n\n\t/* Mapping from a distance to a distance code. dist is the distance - 1 and\n\t * must not have side effects. dist_code[256] and dist_code[257] are never\n\t * used.\n\t */\n\tfunction D_CODE(dist) {\n\t\treturn (dist < 256 ? dist_code[dist] : dist_code[256 + (dist >> 7)]) & 0xff;\n\t}\n\n\t/* ==========================================================================\n\t * Compares to subtrees, using the tree depth as tie breaker when\n\t * the subtrees have equal frequency. This minimizes the worst case length.\n\t */\n\tfunction SMALLER(tree, n, m) {\n\t\treturn tree[n].fc < tree[m].fc || (tree[n].fc === tree[m].fc && depth[n] <= depth[m]);\n\t}\n\n\t/* ==========================================================================\n\t * read string data\n\t */\n\tfunction read_buff(buff, offset, n) {\n\t\tvar i;\n\t\tfor (i = 0; i < n && deflate_pos < deflate_data.length; i++) {\n\t\t\tbuff[offset + i] = deflate_data[deflate_pos++] & 0xff;\n\t\t}\n\t\treturn i;\n\t}\n\n\t/* ==========================================================================\n\t * Initialize the \"longest match\" routines for a new file\n\t */\n\tfunction lm_init() {\n\t\tvar j;\n\n\t\t// Initialize the hash table. */\n\t\tfor (j = 0; j < HASH_SIZE; j++) {\n\t\t\t// head2(j, NIL);\n\t\t\tprev[WSIZE + j] = 0;\n\t\t}\n\t\t// prev will be initialized on the fly */\n\n\t\t// Set the default configuration parameters:\n\t\tmax_lazy_match = configuration_table[compr_level].max_lazy;\n\t\tgood_match = configuration_table[compr_level].good_length;\n\t\tif (!FULL_SEARCH) {\n\t\t\tnice_match = configuration_table[compr_level].nice_length;\n\t\t}\n\t\tmax_chain_length = configuration_table[compr_level].max_chain;\n\n\t\tstrstart = 0;\n\t\tblock_start = 0;\n\n\t\tlookahead = read_buff(window, 0, 2 * WSIZE);\n\t\tif (lookahead <= 0) {\n\t\t\teofile = true;\n\t\t\tlookahead = 0;\n\t\t\treturn;\n\t\t}\n\t\teofile = false;\n\t\t// Make sure that we always have enough lookahead. This is important\n\t\t// if input comes from a device such as a tty.\n\t\twhile (lookahead < MIN_LOOKAHEAD && !eofile) {\n\t\t\tfill_window();\n\t\t}\n\n\t\t// If lookahead < MIN_MATCH, ins_h is garbage, but this is\n\t\t// not important since only literal bytes will be emitted.\n\t\tins_h = 0;\n\t\tfor (j = 0; j < MIN_MATCH - 1; j++) {\n\t\t\t// UPDATE_HASH(ins_h, window[j]);\n\t\t\tins_h = ((ins_h << H_SHIFT) ^ (window[j] & 0xff)) & HASH_MASK;\n\t\t}\n\t}\n\n\t/* ==========================================================================\n\t * Set match_start to the longest match starting at the given string and\n\t * return its length. Matches shorter or equal to prev_length are discarded,\n\t * in which case the result is equal to prev_length and match_start is\n\t * garbage.\n\t * IN assertions: cur_match is the head of the hash chain for the current\n\t *   string (strstart) and its distance is <= MAX_DIST, and prev_length >= 1\n\t */\n\tfunction longest_match(cur_match) {\n\t\tvar chain_length = max_chain_length; // max hash chain length\n\t\tvar scanp = strstart; // current string\n\t\tvar matchp; // matched string\n\t\tvar len; // length of current match\n\t\tvar best_len = prev_length; // best match length so far\n\n\t\t// Stop when cur_match becomes <= limit. To simplify the code,\n\t\t// we prevent matches with the string of window index 0.\n\t\tvar limit = (strstart > MAX_DIST ? strstart - MAX_DIST : NIL);\n\n\t\tvar strendp = strstart + MAX_MATCH;\n\t\tvar scan_end1 = window[scanp + best_len - 1];\n\t\tvar scan_end = window[scanp + best_len];\n\n\t\tvar i, broke;\n\n\t\t// Do not waste too much time if we already have a good match: */\n\t\tif (prev_length >= good_match) {\n\t\t\tchain_length >>= 2;\n\t\t}\n\n\t\t// Assert(encoder->strstart <= window_size-MIN_LOOKAHEAD, \"insufficient lookahead\");\n\n\t\tdo {\n\t\t\t// Assert(cur_match < encoder->strstart, \"no future\");\n\t\t\tmatchp = cur_match;\n\n\t\t\t// Skip to next match if the match length cannot increase\n\t\t\t// or if the match length is less than 2:\n\t\t\tif (window[matchp + best_len] !== scan_end  ||\n\t\t\t\t\twindow[matchp + best_len - 1] !== scan_end1 ||\n\t\t\t\t\twindow[matchp] !== window[scanp] ||\n\t\t\t\t\twindow[++matchp] !== window[scanp + 1]) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\t// The check at best_len-1 can be removed because it will be made\n\t\t\t// again later. (This heuristic is not always a win.)\n\t\t\t// It is not necessary to compare scan[2] and match[2] since they\n\t\t\t// are always equal when the other bytes match, given that\n\t\t\t// the hash keys are equal and that HASH_BITS >= 8.\n\t\t\tscanp += 2;\n\t\t\tmatchp++;\n\n\t\t\t// We check for insufficient lookahead only every 8th comparison;\n\t\t\t// the 256th check will be made at strstart+258.\n\t\t\twhile (scanp < strendp) {\n\t\t\t\tbroke = false;\n\t\t\t\tfor (i = 0; i < 8; i += 1) {\n\t\t\t\t\tscanp += 1;\n\t\t\t\t\tmatchp += 1;\n\t\t\t\t\tif (window[scanp] !== window[matchp]) {\n\t\t\t\t\t\tbroke = true;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif (broke) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tlen = MAX_MATCH - (strendp - scanp);\n\t\t\tscanp = strendp - MAX_MATCH;\n\n\t\t\tif (len > best_len) {\n\t\t\t\tmatch_start = cur_match;\n\t\t\t\tbest_len = len;\n\t\t\t\tif (FULL_SEARCH) {\n\t\t\t\t\tif (len >= MAX_MATCH) {\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tif (len >= nice_match) {\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tscan_end1 = window[scanp + best_len - 1];\n\t\t\t\tscan_end = window[scanp + best_len];\n\t\t\t}\n\t\t} while ((cur_match = prev[cur_match & WMASK]) > limit && --chain_length !== 0);\n\n\t\treturn best_len;\n\t}\n\n\t/* ==========================================================================\n\t * Fill the window when the lookahead becomes insufficient.\n\t * Updates strstart and lookahead, and sets eofile if end of input file.\n\t * IN assertion: lookahead < MIN_LOOKAHEAD && strstart + lookahead > 0\n\t * OUT assertions: at least one byte has been read, or eofile is set;\n\t *    file reads are performed for at least two bytes (required for the\n\t *    translate_eol option).\n\t */\n\tfunction fill_window() {\n\t\tvar n, m;\n\n\t // Amount of free space at the end of the window.\n\t\tvar more = window_size - lookahead - strstart;\n\n\t\t// If the window is almost full and there is insufficient lookahead,\n\t\t// move the upper half to the lower one to make room in the upper half.\n\t\tif (more === -1) {\n\t\t\t// Very unlikely, but possible on 16 bit machine if strstart == 0\n\t\t\t// and lookahead == 1 (input done one byte at time)\n\t\t\tmore--;\n\t\t} else if (strstart >= WSIZE + MAX_DIST) {\n\t\t\t// By the IN assertion, the window is not empty so we can't confuse\n\t\t\t// more == 0 with more == 64K on a 16 bit machine.\n\t\t\t// Assert(window_size == (ulg)2*WSIZE, \"no sliding with BIG_MEM\");\n\n\t\t\t// System.arraycopy(window, WSIZE, window, 0, WSIZE);\n\t\t\tfor (n = 0; n < WSIZE; n++) {\n\t\t\t\twindow[n] = window[n + WSIZE];\n\t\t\t}\n\n\t\t\tmatch_start -= WSIZE;\n\t\t\tstrstart    -= WSIZE; /* we now have strstart >= MAX_DIST: */\n\t\t\tblock_start -= WSIZE;\n\n\t\t\tfor (n = 0; n < HASH_SIZE; n++) {\n\t\t\t\tm = head1(n);\n\t\t\t\thead2(n, m >= WSIZE ? m - WSIZE : NIL);\n\t\t\t}\n\t\t\tfor (n = 0; n < WSIZE; n++) {\n\t\t\t// If n is not on any hash chain, prev[n] is garbage but\n\t\t\t// its value will never be used.\n\t\t\t\tm = prev[n];\n\t\t\t\tprev[n] = (m >= WSIZE ? m - WSIZE : NIL);\n\t\t\t}\n\t\t\tmore += WSIZE;\n\t\t}\n\t\t// At this point, more >= 2\n\t\tif (!eofile) {\n\t\t\tn = read_buff(window, strstart + lookahead, more);\n\t\t\tif (n <= 0) {\n\t\t\t\teofile = true;\n\t\t\t} else {\n\t\t\t\tlookahead += n;\n\t\t\t}\n\t\t}\n\t}\n\n\t/* ==========================================================================\n\t * Processes a new input file and return its compressed length. This\n\t * function does not perform lazy evaluationof matches and inserts\n\t * new strings in the dictionary only for unmatched strings or for short\n\t * matches. It is used only for the fast compression options.\n\t */\n\tfunction deflate_fast() {\n\t\twhile (lookahead !== 0 && qhead === null) {\n\t\t\tvar flush; // set if current block must be flushed\n\n\t\t\t// Insert the string window[strstart .. strstart+2] in the\n\t\t\t// dictionary, and set hash_head to the head of the hash chain:\n\t\t\tINSERT_STRING();\n\n\t\t\t// Find the longest match, discarding those <= prev_length.\n\t\t\t// At this point we have always match_length < MIN_MATCH\n\t\t\tif (hash_head !== NIL && strstart - hash_head <= MAX_DIST) {\n\t\t\t\t// To simplify the code, we prevent matches with the string\n\t\t\t\t// of window index 0 (in particular we have to avoid a match\n\t\t\t\t// of the string with itself at the start of the input file).\n\t\t\t\tmatch_length = longest_match(hash_head);\n\t\t\t\t// longest_match() sets match_start */\n\t\t\t\tif (match_length > lookahead) {\n\t\t\t\t\tmatch_length = lookahead;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (match_length >= MIN_MATCH) {\n\t\t\t\t// check_match(strstart, match_start, match_length);\n\n\t\t\t\tflush = ct_tally(strstart - match_start, match_length - MIN_MATCH);\n\t\t\t\tlookahead -= match_length;\n\n\t\t\t\t// Insert new strings in the hash table only if the match length\n\t\t\t\t// is not too large. This saves time but degrades compression.\n\t\t\t\tif (match_length <= max_lazy_match) {\n\t\t\t\t\tmatch_length--; // string at strstart already in hash table\n\t\t\t\t\tdo {\n\t\t\t\t\t\tstrstart++;\n\t\t\t\t\t\tINSERT_STRING();\n\t\t\t\t\t\t// strstart never exceeds WSIZE-MAX_MATCH, so there are\n\t\t\t\t\t\t// always MIN_MATCH bytes ahead. If lookahead < MIN_MATCH\n\t\t\t\t\t\t// these bytes are garbage, but it does not matter since\n\t\t\t\t\t\t// the next lookahead bytes will be emitted as literals.\n\t\t\t\t\t} while (--match_length !== 0);\n\t\t\t\t\tstrstart++;\n\t\t\t\t} else {\n\t\t\t\t\tstrstart += match_length;\n\t\t\t\t\tmatch_length = 0;\n\t\t\t\t\tins_h = window[strstart] & 0xff;\n\t\t\t\t\t// UPDATE_HASH(ins_h, window[strstart + 1]);\n\t\t\t\t\tins_h = ((ins_h << H_SHIFT) ^ (window[strstart + 1] & 0xff)) & HASH_MASK;\n\n\t\t\t\t//#if MIN_MATCH !== 3\n\t\t\t\t//\t\tCall UPDATE_HASH() MIN_MATCH-3 more times\n\t\t\t\t//#endif\n\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\t// No match, output a literal byte */\n\t\t\t\tflush = ct_tally(0, window[strstart] & 0xff);\n\t\t\t\tlookahead--;\n\t\t\t\tstrstart++;\n\t\t\t}\n\t\t\tif (flush) {\n\t\t\t\tflush_block(0);\n\t\t\t\tblock_start = strstart;\n\t\t\t}\n\n\t\t\t// Make sure that we always have enough lookahead, except\n\t\t\t// at the end of the input file. We need MAX_MATCH bytes\n\t\t\t// for the next match, plus MIN_MATCH bytes to insert the\n\t\t\t// string following the next match.\n\t\t\twhile (lookahead < MIN_LOOKAHEAD && !eofile) {\n\t\t\t\tfill_window();\n\t\t\t}\n\t\t}\n\t}\n\n\tfunction deflate_better() {\n\t\t// Process the input block. */\n\t\twhile (lookahead !== 0 && qhead === null) {\n\t\t\t// Insert the string window[strstart .. strstart+2] in the\n\t\t\t// dictionary, and set hash_head to the head of the hash chain:\n\t\t\tINSERT_STRING();\n\n\t\t\t// Find the longest match, discarding those <= prev_length.\n\t\t\tprev_length = match_length;\n\t\t\tprev_match = match_start;\n\t\t\tmatch_length = MIN_MATCH - 1;\n\n\t\t\tif (hash_head !== NIL && prev_length < max_lazy_match && strstart - hash_head <= MAX_DIST) {\n\t\t\t\t// To simplify the code, we prevent matches with the string\n\t\t\t\t// of window index 0 (in particular we have to avoid a match\n\t\t\t\t// of the string with itself at the start of the input file).\n\t\t\t\tmatch_length = longest_match(hash_head);\n\t\t\t\t// longest_match() sets match_start */\n\t\t\t\tif (match_length > lookahead) {\n\t\t\t\t\tmatch_length = lookahead;\n\t\t\t\t}\n\n\t\t\t\t// Ignore a length 3 match if it is too distant: */\n\t\t\t\tif (match_length === MIN_MATCH && strstart - match_start > TOO_FAR) {\n\t\t\t\t\t// If prev_match is also MIN_MATCH, match_start is garbage\n\t\t\t\t\t// but we will ignore the current match anyway.\n\t\t\t\t\tmatch_length--;\n\t\t\t\t}\n\t\t\t}\n\t\t\t// If there was a match at the previous step and the current\n\t\t\t// match is not better, output the previous match:\n\t\t\tif (prev_length >= MIN_MATCH && match_length <= prev_length) {\n\t\t\t\tvar flush; // set if current block must be flushed\n\n\t\t\t\t// check_match(strstart - 1, prev_match, prev_length);\n\t\t\t\tflush = ct_tally(strstart - 1 - prev_match, prev_length - MIN_MATCH);\n\n\t\t\t\t// Insert in hash table all strings up to the end of the match.\n\t\t\t\t// strstart-1 and strstart are already inserted.\n\t\t\t\tlookahead -= prev_length - 1;\n\t\t\t\tprev_length -= 2;\n\t\t\t\tdo {\n\t\t\t\t\tstrstart++;\n\t\t\t\t\tINSERT_STRING();\n\t\t\t\t\t// strstart never exceeds WSIZE-MAX_MATCH, so there are\n\t\t\t\t\t// always MIN_MATCH bytes ahead. If lookahead < MIN_MATCH\n\t\t\t\t\t// these bytes are garbage, but it does not matter since the\n\t\t\t\t\t// next lookahead bytes will always be emitted as literals.\n\t\t\t\t} while (--prev_length !== 0);\n\t\t\t\tmatch_available = false;\n\t\t\t\tmatch_length = MIN_MATCH - 1;\n\t\t\t\tstrstart++;\n\t\t\t\tif (flush) {\n\t\t\t\t\tflush_block(0);\n\t\t\t\t\tblock_start = strstart;\n\t\t\t\t}\n\t\t\t} else if (match_available) {\n\t\t\t\t// If there was no match at the previous position, output a\n\t\t\t\t// single literal. If there was a match but the current match\n\t\t\t\t// is longer, truncate the previous match to a single literal.\n\t\t\t\tif (ct_tally(0, window[strstart - 1] & 0xff)) {\n\t\t\t\t\tflush_block(0);\n\t\t\t\t\tblock_start = strstart;\n\t\t\t\t}\n\t\t\t\tstrstart++;\n\t\t\t\tlookahead--;\n\t\t\t} else {\n\t\t\t\t// There is no previous match to compare with, wait for\n\t\t\t\t// the next step to decide.\n\t\t\t\tmatch_available = true;\n\t\t\t\tstrstart++;\n\t\t\t\tlookahead--;\n\t\t\t}\n\n\t\t\t// Make sure that we always have enough lookahead, except\n\t\t\t// at the end of the input file. We need MAX_MATCH bytes\n\t\t\t// for the next match, plus MIN_MATCH bytes to insert the\n\t\t\t// string following the next match.\n\t\t\twhile (lookahead < MIN_LOOKAHEAD && !eofile) {\n\t\t\t\tfill_window();\n\t\t\t}\n\t\t}\n\t}\n\n\tfunction init_deflate() {\n\t\tif (eofile) {\n\t\t\treturn;\n\t\t}\n\t\tbi_buf = 0;\n\t\tbi_valid = 0;\n\t\tct_init();\n\t\tlm_init();\n\n\t\tqhead = null;\n\t\toutcnt = 0;\n\t\toutoff = 0;\n\n\t\tif (compr_level <= 3) {\n\t\t\tprev_length = MIN_MATCH - 1;\n\t\t\tmatch_length = 0;\n\t\t} else {\n\t\t\tmatch_length = MIN_MATCH - 1;\n\t\t\tmatch_available = false;\n\t\t}\n\n\t\tcomplete = false;\n\t}\n\n\t/* ==========================================================================\n\t * Same as above, but achieves better compression. We use a lazy\n\t * evaluation for matches: a match is finally adopted only if there is\n\t * no better match at the next window position.\n\t */\n\tfunction deflate_internal(buff, off, buff_size) {\n\t\tvar n;\n\n\t\tif (!initflag) {\n\t\t\tinit_deflate();\n\t\t\tinitflag = true;\n\t\t\tif (lookahead === 0) { // empty\n\t\t\t\tcomplete = true;\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t}\n\n\t\tn = qcopy(buff, off, buff_size);\n\t\tif (n === buff_size) {\n\t\t\treturn buff_size;\n\t\t}\n\n\t\tif (complete) {\n\t\t\treturn n;\n\t\t}\n\n\t\tif (compr_level <= 3) {\n\t\t\t// optimized for speed\n\t\t\tdeflate_fast();\n\t\t} else {\n\t\t\tdeflate_better();\n\t\t}\n\n\t\tif (lookahead === 0) {\n\t\t\tif (match_available) {\n\t\t\t\tct_tally(0, window[strstart - 1] & 0xff);\n\t\t\t}\n\t\t\tflush_block(1);\n\t\t\tcomplete = true;\n\t\t}\n\n\t\treturn n + qcopy(buff, n + off, buff_size - n);\n\t}\n\n\tfunction qcopy(buff, off, buff_size) {\n\t\tvar n, i, j;\n\n\t\tn = 0;\n\t\twhile (qhead !== null && n < buff_size) {\n\t\t\ti = buff_size - n;\n\t\t\tif (i > qhead.len) {\n\t\t\t\ti = qhead.len;\n\t\t\t}\n\t\t\t// System.arraycopy(qhead.ptr, qhead.off, buff, off + n, i);\n\t\t\tfor (j = 0; j < i; j++) {\n\t\t\t\tbuff[off + n + j] = qhead.ptr[qhead.off + j];\n\t\t\t}\n\n\t\t\tqhead.off += i;\n\t\t\tqhead.len -= i;\n\t\t\tn += i;\n\t\t\tif (qhead.len === 0) {\n\t\t\t\tvar p;\n\t\t\t\tp = qhead;\n\t\t\t\tqhead = qhead.next;\n\t\t\t\treuse_queue(p);\n\t\t\t}\n\t\t}\n\n\t\tif (n === buff_size) {\n\t\t\treturn n;\n\t\t}\n\n\t\tif (outoff < outcnt) {\n\t\t\ti = buff_size - n;\n\t\t\tif (i > outcnt - outoff) {\n\t\t\t\ti = outcnt - outoff;\n\t\t\t}\n\t\t\t// System.arraycopy(outbuf, outoff, buff, off + n, i);\n\t\t\tfor (j = 0; j < i; j++) {\n\t\t\t\tbuff[off + n + j] = outbuf[outoff + j];\n\t\t\t}\n\t\t\toutoff += i;\n\t\t\tn += i;\n\t\t\tif (outcnt === outoff) {\n\t\t\t\toutcnt = outoff = 0;\n\t\t\t}\n\t\t}\n\t\treturn n;\n\t}\n\n\t/* ==========================================================================\n\t * Allocate the match buffer, initialize the various tables and save the\n\t * location of the internal file attribute (ascii/binary) and method\n\t * (DEFLATE/STORE).\n\t */\n\tfunction ct_init() {\n\t\tvar n; // iterates over tree elements\n\t\tvar bits; // bit counter\n\t\tvar length; // length value\n\t\tvar code; // code value\n\t\tvar dist; // distance index\n\n\t\tif (static_dtree[0].dl !== 0) {\n\t\t\treturn; // ct_init already called\n\t\t}\n\n\t\tl_desc.dyn_tree = dyn_ltree;\n\t\tl_desc.static_tree = static_ltree;\n\t\tl_desc.extra_bits = extra_lbits;\n\t\tl_desc.extra_base = LITERALS + 1;\n\t\tl_desc.elems = L_CODES;\n\t\tl_desc.max_length = MAX_BITS;\n\t\tl_desc.max_code = 0;\n\n\t\td_desc.dyn_tree = dyn_dtree;\n\t\td_desc.static_tree = static_dtree;\n\t\td_desc.extra_bits = extra_dbits;\n\t\td_desc.extra_base = 0;\n\t\td_desc.elems = D_CODES;\n\t\td_desc.max_length = MAX_BITS;\n\t\td_desc.max_code = 0;\n\n\t\tbl_desc.dyn_tree = bl_tree;\n\t\tbl_desc.static_tree = null;\n\t\tbl_desc.extra_bits = extra_blbits;\n\t\tbl_desc.extra_base = 0;\n\t\tbl_desc.elems = BL_CODES;\n\t\tbl_desc.max_length = MAX_BL_BITS;\n\t\tbl_desc.max_code = 0;\n\n\t // Initialize the mapping length (0..255) -> length code (0..28)\n\t\tlength = 0;\n\t\tfor (code = 0; code < LENGTH_CODES - 1; code++) {\n\t\t\tbase_length[code] = length;\n\t\t\tfor (n = 0; n < (1 << extra_lbits[code]); n++) {\n\t\t\t\tlength_code[length++] = code;\n\t\t\t}\n\t\t}\n\t // Assert (length === 256, \"ct_init: length !== 256\");\n\n\t\t// Note that the length 255 (match length 258) can be represented\n\t\t// in two different ways: code 284 + 5 bits or code 285, so we\n\t\t// overwrite length_code[255] to use the best encoding:\n\t\tlength_code[length - 1] = code;\n\n\t\t// Initialize the mapping dist (0..32K) -> dist code (0..29) */\n\t\tdist = 0;\n\t\tfor (code = 0; code < 16; code++) {\n\t\t\tbase_dist[code] = dist;\n\t\t\tfor (n = 0; n < (1 << extra_dbits[code]); n++) {\n\t\t\t\tdist_code[dist++] = code;\n\t\t\t}\n\t\t}\n\t\t// Assert (dist === 256, \"ct_init: dist !== 256\");\n\t\t// from now on, all distances are divided by 128\n\t\tfor (dist >>= 7; code < D_CODES; code++) {\n\t\t\tbase_dist[code] = dist << 7;\n\t\t\tfor (n = 0; n < (1 << (extra_dbits[code] - 7)); n++) {\n\t\t\t\tdist_code[256 + dist++] = code;\n\t\t\t}\n\t\t}\n\t\t// Assert (dist === 256, \"ct_init: 256+dist !== 512\");\n\n\t\t// Construct the codes of the static literal tree\n\t\tfor (bits = 0; bits <= MAX_BITS; bits++) {\n\t\t\tbl_count[bits] = 0;\n\t\t}\n\t\tn = 0;\n\t\twhile (n <= 143) {\n\t\t\tstatic_ltree[n++].dl = 8;\n\t\t\tbl_count[8]++;\n\t\t}\n\t\twhile (n <= 255) {\n\t\t\tstatic_ltree[n++].dl = 9;\n\t\t\tbl_count[9]++;\n\t\t}\n\t\twhile (n <= 279) {\n\t\t\tstatic_ltree[n++].dl = 7;\n\t\t\tbl_count[7]++;\n\t\t}\n\t\twhile (n <= 287) {\n\t\t\tstatic_ltree[n++].dl = 8;\n\t\t\tbl_count[8]++;\n\t\t}\n\t\t// Codes 286 and 287 do not exist, but we must include them in the\n\t\t// tree construction to get a canonical Huffman tree (longest code\n\t\t// all ones)\n\t\tgen_codes(static_ltree, L_CODES + 1);\n\n\t\t// The static distance tree is trivial: */\n\t\tfor (n = 0; n < D_CODES; n++) {\n\t\t\tstatic_dtree[n].dl = 5;\n\t\t\tstatic_dtree[n].fc = bi_reverse(n, 5);\n\t\t}\n\n\t\t// Initialize the first block of the first file:\n\t\tinit_block();\n\t}\n\n\t/* ==========================================================================\n\t * Initialize a new block.\n\t */\n\tfunction init_block() {\n\t\tvar n; // iterates over tree elements\n\n\t\t// Initialize the trees.\n\t\tfor (n = 0; n < L_CODES;  n++) {\n\t\t\tdyn_ltree[n].fc = 0;\n\t\t}\n\t\tfor (n = 0; n < D_CODES;  n++) {\n\t\t\tdyn_dtree[n].fc = 0;\n\t\t}\n\t\tfor (n = 0; n < BL_CODES; n++) {\n\t\t\tbl_tree[n].fc = 0;\n\t\t}\n\n\t\tdyn_ltree[END_BLOCK].fc = 1;\n\t\topt_len = static_len = 0;\n\t\tlast_lit = last_dist = last_flags = 0;\n\t\tflags = 0;\n\t\tflag_bit = 1;\n\t}\n\n\t/* ==========================================================================\n\t * Restore the heap property by moving down the tree starting at node k,\n\t * exchanging a node with the smallest of its two sons if necessary, stopping\n\t * when the heap property is re-established (each father smaller than its\n\t * two sons).\n\t *\n\t * @param tree- tree to restore\n\t * @param k- node to move down\n\t */\n\tfunction pqdownheap(tree, k) {\n\t\tvar v = heap[k],\n\t\t\tj = k << 1; // left son of k\n\n\t\twhile (j <= heap_len) {\n\t\t\t// Set j to the smallest of the two sons:\n\t\t\tif (j < heap_len && SMALLER(tree, heap[j + 1], heap[j])) {\n\t\t\t\tj++;\n\t\t\t}\n\n\t\t\t// Exit if v is smaller than both sons\n\t\t\tif (SMALLER(tree, v, heap[j])) {\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t// Exchange v with the smallest son\n\t\t\theap[k] = heap[j];\n\t\t\tk = j;\n\n\t\t\t// And continue down the tree, setting j to the left son of k\n\t\t\tj <<= 1;\n\t\t}\n\t\theap[k] = v;\n\t}\n\n\t/* ==========================================================================\n\t * Compute the optimal bit lengths for a tree and update the total bit length\n\t * for the current block.\n\t * IN assertion: the fields freq and dad are set, heap[heap_max] and\n\t *    above are the tree nodes sorted by increasing frequency.\n\t * OUT assertions: the field len is set to the optimal bit length, the\n\t *     array bl_count contains the frequencies for each bit length.\n\t *     The length opt_len is updated; static_len is also updated if stree is\n\t *     not null.\n\t */\n\tfunction gen_bitlen(desc) { // the tree descriptor\n\t\tvar tree = desc.dyn_tree;\n\t\tvar extra = desc.extra_bits;\n\t\tvar base = desc.extra_base;\n\t\tvar max_code = desc.max_code;\n\t\tvar max_length = desc.max_length;\n\t\tvar stree = desc.static_tree;\n\t\tvar h; // heap index\n\t\tvar n, m; // iterate over the tree elements\n\t\tvar bits; // bit length\n\t\tvar xbits; // extra bits\n\t\tvar f; // frequency\n\t\tvar overflow = 0; // number of elements with bit length too large\n\n\t\tfor (bits = 0; bits <= MAX_BITS; bits++) {\n\t\t\tbl_count[bits] = 0;\n\t\t}\n\n\t\t// In a first pass, compute the optimal bit lengths (which may\n\t\t// overflow in the case of the bit length tree).\n\t\ttree[heap[heap_max]].dl = 0; // root of the heap\n\n\t\tfor (h = heap_max + 1; h < HEAP_SIZE; h++) {\n\t\t\tn = heap[h];\n\t\t\tbits = tree[tree[n].dl].dl + 1;\n\t\t\tif (bits > max_length) {\n\t\t\t\tbits = max_length;\n\t\t\t\toverflow++;\n\t\t\t}\n\t\t\ttree[n].dl = bits;\n\t\t\t// We overwrite tree[n].dl which is no longer needed\n\n\t\t\tif (n > max_code) {\n\t\t\t\tcontinue; // not a leaf node\n\t\t\t}\n\n\t\t\tbl_count[bits]++;\n\t\t\txbits = 0;\n\t\t\tif (n >= base) {\n\t\t\t\txbits = extra[n - base];\n\t\t\t}\n\t\t\tf = tree[n].fc;\n\t\t\topt_len += f * (bits + xbits);\n\t\t\tif (stree !== null) {\n\t\t\t\tstatic_len += f * (stree[n].dl + xbits);\n\t\t\t}\n\t\t}\n\t\tif (overflow === 0) {\n\t\t\treturn;\n\t\t}\n\n\t\t// This happens for example on obj2 and pic of the Calgary corpus\n\n\t\t// Find the first bit length which could increase:\n\t\tdo {\n\t\t\tbits = max_length - 1;\n\t\t\twhile (bl_count[bits] === 0) {\n\t\t\t\tbits--;\n\t\t\t}\n\t\t\tbl_count[bits]--; // move one leaf down the tree\n\t\t\tbl_count[bits + 1] += 2; // move one overflow item as its brother\n\t\t\tbl_count[max_length]--;\n\t\t\t// The brother of the overflow item also moves one step up,\n\t\t\t// but this does not affect bl_count[max_length]\n\t\t\toverflow -= 2;\n\t\t} while (overflow > 0);\n\n\t\t// Now recompute all bit lengths, scanning in increasing frequency.\n\t\t// h is still equal to HEAP_SIZE. (It is simpler to reconstruct all\n\t\t// lengths instead of fixing only the wrong ones. This idea is taken\n\t\t// from 'ar' written by Haruhiko Okumura.)\n\t\tfor (bits = max_length; bits !== 0; bits--) {\n\t\t\tn = bl_count[bits];\n\t\t\twhile (n !== 0) {\n\t\t\t\tm = heap[--h];\n\t\t\t\tif (m > max_code) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tif (tree[m].dl !== bits) {\n\t\t\t\t\topt_len += (bits - tree[m].dl) * tree[m].fc;\n\t\t\t\t\ttree[m].fc = bits;\n\t\t\t\t}\n\t\t\t\tn--;\n\t\t\t}\n\t\t}\n\t}\n\n\t  /* ==========================================================================\n\t   * Generate the codes for a given tree and bit counts (which need not be\n\t   * optimal).\n\t   * IN assertion: the array bl_count contains the bit length statistics for\n\t   * the given tree and the field len is set for all tree elements.\n\t   * OUT assertion: the field code is set for all tree elements of non\n\t   *     zero code length.\n\t   * @param tree- the tree to decorate\n\t   * @param max_code- largest code with non-zero frequency\n\t   */\n\tfunction gen_codes(tree, max_code) {\n\t\tvar next_code = []; // new Array(MAX_BITS + 1); // next code value for each bit length\n\t\tvar code = 0; // running code value\n\t\tvar bits; // bit index\n\t\tvar n; // code index\n\n\t\t// The distribution counts are first used to generate the code values\n\t\t// without bit reversal.\n\t\tfor (bits = 1; bits <= MAX_BITS; bits++) {\n\t\t\tcode = ((code + bl_count[bits - 1]) << 1);\n\t\t\tnext_code[bits] = code;\n\t\t}\n\n\t\t// Check that the bit counts in bl_count are consistent. The last code\n\t\t// must be all ones.\n\t\t// Assert (code + encoder->bl_count[MAX_BITS]-1 === (1<<MAX_BITS)-1, \"inconsistent bit counts\");\n\t\t// Tracev((stderr,\"\\ngen_codes: max_code %d \", max_code));\n\n\t\tfor (n = 0; n <= max_code; n++) {\n\t\t\tvar len = tree[n].dl;\n\t\t\tif (len === 0) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\t// Now reverse the bits\n\t\t\ttree[n].fc = bi_reverse(next_code[len]++, len);\n\n\t\t\t// Tracec(tree !== static_ltree, (stderr,\"\\nn %3d %c l %2d c %4x (%x) \", n, (isgraph(n) ? n : ' '), len, tree[n].fc, next_code[len]-1));\n\t\t}\n\t}\n\n\t/* ==========================================================================\n\t * Construct one Huffman tree and assigns the code bit strings and lengths.\n\t * Update the total bit length for the current block.\n\t * IN assertion: the field freq is set for all tree elements.\n\t * OUT assertions: the fields len and code are set to the optimal bit length\n\t *     and corresponding code. The length opt_len is updated; static_len is\n\t *     also updated if stree is not null. The field max_code is set.\n\t */\n\tfunction build_tree(desc) { // the tree descriptor\n\t\tvar tree = desc.dyn_tree;\n\t\tvar stree = desc.static_tree;\n\t\tvar elems = desc.elems;\n\t\tvar n, m; // iterate over heap elements\n\t\tvar max_code = -1; // largest code with non zero frequency\n\t\tvar node = elems; // next internal node of the tree\n\n\t\t// Construct the initial heap, with least frequent element in\n\t\t// heap[SMALLEST]. The sons of heap[n] are heap[2*n] and heap[2*n+1].\n\t\t// heap[0] is not used.\n\t\theap_len = 0;\n\t\theap_max = HEAP_SIZE;\n\n\t\tfor (n = 0; n < elems; n++) {\n\t\t\tif (tree[n].fc !== 0) {\n\t\t\t\theap[++heap_len] = max_code = n;\n\t\t\t\tdepth[n] = 0;\n\t\t\t} else {\n\t\t\t\ttree[n].dl = 0;\n\t\t\t}\n\t\t}\n\n\t\t// The pkzip format requires that at least one distance code exists,\n\t\t// and that at least one bit should be sent even if there is only one\n\t\t// possible code. So to avoid special checks later on we force at least\n\t\t// two codes of non zero frequency.\n\t\twhile (heap_len < 2) {\n\t\t\tvar xnew = heap[++heap_len] = (max_code < 2 ? ++max_code : 0);\n\t\t\ttree[xnew].fc = 1;\n\t\t\tdepth[xnew] = 0;\n\t\t\topt_len--;\n\t\t\tif (stree !== null) {\n\t\t\t\tstatic_len -= stree[xnew].dl;\n\t\t\t}\n\t\t\t// new is 0 or 1 so it does not have extra bits\n\t\t}\n\t\tdesc.max_code = max_code;\n\n\t\t// The elements heap[heap_len/2+1 .. heap_len] are leaves of the tree,\n\t\t// establish sub-heaps of increasing lengths:\n\t\tfor (n = heap_len >> 1; n >= 1; n--) {\n\t\t\tpqdownheap(tree, n);\n\t\t}\n\n\t\t// Construct the Huffman tree by repeatedly combining the least two\n\t\t// frequent nodes.\n\t\tdo {\n\t\t\tn = heap[SMALLEST];\n\t\t\theap[SMALLEST] = heap[heap_len--];\n\t\t\tpqdownheap(tree, SMALLEST);\n\n\t\t\tm = heap[SMALLEST]; // m = node of next least frequency\n\n\t\t\t// keep the nodes sorted by frequency\n\t\t\theap[--heap_max] = n;\n\t\t\theap[--heap_max] = m;\n\n\t\t\t// Create a new node father of n and m\n\t\t\ttree[node].fc = tree[n].fc + tree[m].fc;\n\t\t\t//\tdepth[node] = (char)(MAX(depth[n], depth[m]) + 1);\n\t\t\tif (depth[n] > depth[m] + 1) {\n\t\t\t\tdepth[node] = depth[n];\n\t\t\t} else {\n\t\t\t\tdepth[node] = depth[m] + 1;\n\t\t\t}\n\t\t\ttree[n].dl = tree[m].dl = node;\n\n\t\t\t// and insert the new node in the heap\n\t\t\theap[SMALLEST] = node++;\n\t\t\tpqdownheap(tree, SMALLEST);\n\n\t\t} while (heap_len >= 2);\n\n\t\theap[--heap_max] = heap[SMALLEST];\n\n\t\t// At this point, the fields freq and dad are set. We can now\n\t\t// generate the bit lengths.\n\t\tgen_bitlen(desc);\n\n\t\t// The field len is now set, we can generate the bit codes\n\t\tgen_codes(tree, max_code);\n\t}\n\n\t/* ==========================================================================\n\t * Scan a literal or distance tree to determine the frequencies of the codes\n\t * in the bit length tree. Updates opt_len to take into account the repeat\n\t * counts. (The contribution of the bit length codes will be added later\n\t * during the construction of bl_tree.)\n\t *\n\t * @param tree- the tree to be scanned\n\t * @param max_code- and its largest code of non zero frequency\n\t */\n\tfunction scan_tree(tree, max_code) {\n\t\tvar n, // iterates over all tree elements\n\t\t\tprevlen = -1, // last emitted length\n\t\t\tcurlen, // length of current code\n\t\t\tnextlen = tree[0].dl, // length of next code\n\t\t\tcount = 0, // repeat count of the current code\n\t\t\tmax_count = 7, // max repeat count\n\t\t\tmin_count = 4; // min repeat count\n\n\t\tif (nextlen === 0) {\n\t\t\tmax_count = 138;\n\t\t\tmin_count = 3;\n\t\t}\n\t\ttree[max_code + 1].dl = 0xffff; // guard\n\n\t\tfor (n = 0; n <= max_code; n++) {\n\t\t\tcurlen = nextlen;\n\t\t\tnextlen = tree[n + 1].dl;\n\t\t\tif (++count < max_count && curlen === nextlen) {\n\t\t\t\tcontinue;\n\t\t\t} else if (count < min_count) {\n\t\t\t\tbl_tree[curlen].fc += count;\n\t\t\t} else if (curlen !== 0) {\n\t\t\t\tif (curlen !== prevlen) {\n\t\t\t\t\tbl_tree[curlen].fc++;\n\t\t\t\t}\n\t\t\t\tbl_tree[REP_3_6].fc++;\n\t\t\t} else if (count <= 10) {\n\t\t\t\tbl_tree[REPZ_3_10].fc++;\n\t\t\t} else {\n\t\t\t\tbl_tree[REPZ_11_138].fc++;\n\t\t\t}\n\t\t\tcount = 0; prevlen = curlen;\n\t\t\tif (nextlen === 0) {\n\t\t\t\tmax_count = 138;\n\t\t\t\tmin_count = 3;\n\t\t\t} else if (curlen === nextlen) {\n\t\t\t\tmax_count = 6;\n\t\t\t\tmin_count = 3;\n\t\t\t} else {\n\t\t\t\tmax_count = 7;\n\t\t\t\tmin_count = 4;\n\t\t\t}\n\t\t}\n\t}\n\n\t/* ==========================================================================\n\t * Send a literal or distance tree in compressed form, using the codes in\n\t * bl_tree.\n\t *\n\t * @param tree- the tree to be scanned\n\t * @param max_code- and its largest code of non zero frequency\n\t */\n\tfunction send_tree(tree, max_code) {\n\t\tvar n; // iterates over all tree elements\n\t\tvar prevlen = -1; // last emitted length\n\t\tvar curlen; // length of current code\n\t\tvar nextlen = tree[0].dl; // length of next code\n\t\tvar count = 0; // repeat count of the current code\n\t\tvar max_count = 7; // max repeat count\n\t\tvar min_count = 4; // min repeat count\n\n\t\t// tree[max_code+1].dl = -1; */  /* guard already set */\n\t\tif (nextlen === 0) {\n\t\t\tmax_count = 138;\n\t\t\tmin_count = 3;\n\t\t}\n\n\t\tfor (n = 0; n <= max_code; n++) {\n\t\t\tcurlen = nextlen;\n\t\t\tnextlen = tree[n + 1].dl;\n\t\t\tif (++count < max_count && curlen === nextlen) {\n\t\t\t\tcontinue;\n\t\t\t} else if (count < min_count) {\n\t\t\t\tdo {\n\t\t\t\t\tSEND_CODE(curlen, bl_tree);\n\t\t\t\t} while (--count !== 0);\n\t\t\t} else if (curlen !== 0) {\n\t\t\t\tif (curlen !== prevlen) {\n\t\t\t\t\tSEND_CODE(curlen, bl_tree);\n\t\t\t\t\tcount--;\n\t\t\t\t}\n\t\t\t// Assert(count >= 3 && count <= 6, \" 3_6?\");\n\t\t\t\tSEND_CODE(REP_3_6, bl_tree);\n\t\t\t\tsend_bits(count - 3, 2);\n\t\t\t} else if (count <= 10) {\n\t\t\t\tSEND_CODE(REPZ_3_10, bl_tree);\n\t\t\t\tsend_bits(count - 3, 3);\n\t\t\t} else {\n\t\t\t\tSEND_CODE(REPZ_11_138, bl_tree);\n\t\t\t\tsend_bits(count - 11, 7);\n\t\t\t}\n\t\t\tcount = 0;\n\t\t\tprevlen = curlen;\n\t\t\tif (nextlen === 0) {\n\t\t\t\tmax_count = 138;\n\t\t\t\tmin_count = 3;\n\t\t\t} else if (curlen === nextlen) {\n\t\t\t\tmax_count = 6;\n\t\t\t\tmin_count = 3;\n\t\t\t} else {\n\t\t\t\tmax_count = 7;\n\t\t\t\tmin_count = 4;\n\t\t\t}\n\t\t}\n\t}\n\n\t/* ==========================================================================\n\t * Construct the Huffman tree for the bit lengths and return the index in\n\t * bl_order of the last bit length code to send.\n\t */\n\tfunction build_bl_tree() {\n\t\tvar max_blindex; // index of last bit length code of non zero freq\n\n\t\t// Determine the bit length frequencies for literal and distance trees\n\t\tscan_tree(dyn_ltree, l_desc.max_code);\n\t\tscan_tree(dyn_dtree, d_desc.max_code);\n\n\t\t// Build the bit length tree:\n\t\tbuild_tree(bl_desc);\n\t\t// opt_len now includes the length of the tree representations, except\n\t\t// the lengths of the bit lengths codes and the 5+5+4 bits for the counts.\n\n\t\t// Determine the number of bit length codes to send. The pkzip format\n\t\t// requires that at least 4 bit length codes be sent. (appnote.txt says\n\t\t// 3 but the actual value used is 4.)\n\t\tfor (max_blindex = BL_CODES - 1; max_blindex >= 3; max_blindex--) {\n\t\t\tif (bl_tree[bl_order[max_blindex]].dl !== 0) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\t// Update opt_len to include the bit length tree and counts */\n\t\topt_len += 3 * (max_blindex + 1) + 5 + 5 + 4;\n\t\t// Tracev((stderr, \"\\ndyn trees: dyn %ld, stat %ld\",\n\t\t// encoder->opt_len, encoder->static_len));\n\n\t\treturn max_blindex;\n\t}\n\n\t/* ==========================================================================\n\t * Send the header for a block using dynamic Huffman trees: the counts, the\n\t * lengths of the bit length codes, the literal tree and the distance tree.\n\t * IN assertion: lcodes >= 257, dcodes >= 1, blcodes >= 4.\n\t */\n\tfunction send_all_trees(lcodes, dcodes, blcodes) { // number of codes for each tree\n\t\tvar rank; // index in bl_order\n\n\t\t// Assert (lcodes >= 257 && dcodes >= 1 && blcodes >= 4, \"not enough codes\");\n\t\t// Assert (lcodes <= L_CODES && dcodes <= D_CODES && blcodes <= BL_CODES, \"too many codes\");\n\t\t// Tracev((stderr, \"\\nbl counts: \"));\n\t\tsend_bits(lcodes - 257, 5); // not +255 as stated in appnote.txt\n\t\tsend_bits(dcodes - 1,   5);\n\t\tsend_bits(blcodes - 4,  4); // not -3 as stated in appnote.txt\n\t\tfor (rank = 0; rank < blcodes; rank++) {\n\t\t\t// Tracev((stderr, \"\\nbl code %2d \", bl_order[rank]));\n\t\t\tsend_bits(bl_tree[bl_order[rank]].dl, 3);\n\t\t}\n\n\t\t// send the literal tree\n\t\tsend_tree(dyn_ltree, lcodes - 1);\n\n\t\t// send the distance tree\n\t\tsend_tree(dyn_dtree, dcodes - 1);\n\t}\n\n\t/* ==========================================================================\n\t * Determine the best encoding for the current block: dynamic trees, static\n\t * trees or store, and output the encoded block to the zip file.\n\t */\n\tfunction flush_block(eof) { // true if this is the last block for a file\n\t\tvar opt_lenb, static_lenb, // opt_len and static_len in bytes\n\t\t\tmax_blindex, // index of last bit length code of non zero freq\n\t\t\tstored_len, // length of input block\n\t\t\ti;\n\n\t\tstored_len = strstart - block_start;\n\t\tflag_buf[last_flags] = flags; // Save the flags for the last 8 items\n\n\t\t// Construct the literal and distance trees\n\t\tbuild_tree(l_desc);\n\t\t// Tracev((stderr, \"\\nlit data: dyn %ld, stat %ld\",\n\t\t// encoder->opt_len, encoder->static_len));\n\n\t\tbuild_tree(d_desc);\n\t\t// Tracev((stderr, \"\\ndist data: dyn %ld, stat %ld\",\n\t\t// encoder->opt_len, encoder->static_len));\n\t\t// At this point, opt_len and static_len are the total bit lengths of\n\t\t// the compressed block data, excluding the tree representations.\n\n\t\t// Build the bit length tree for the above two trees, and get the index\n\t\t// in bl_order of the last bit length code to send.\n\t\tmax_blindex = build_bl_tree();\n\n\t // Determine the best encoding. Compute first the block length in bytes\n\t\topt_lenb = (opt_len + 3 + 7) >> 3;\n\t\tstatic_lenb = (static_len + 3 + 7) >> 3;\n\n\t//  Trace((stderr, \"\\nopt %lu(%lu) stat %lu(%lu) stored %lu lit %u dist %u \", opt_lenb, encoder->opt_len, static_lenb, encoder->static_len, stored_len, encoder->last_lit, encoder->last_dist));\n\n\t\tif (static_lenb <= opt_lenb) {\n\t\t\topt_lenb = static_lenb;\n\t\t}\n\t\tif (stored_len + 4 <= opt_lenb && block_start >= 0) { // 4: two words for the lengths\n\t\t\t// The test buf !== NULL is only necessary if LIT_BUFSIZE > WSIZE.\n\t\t\t// Otherwise we can't have processed more than WSIZE input bytes since\n\t\t\t// the last block flush, because compression would have been\n\t\t\t// successful. If LIT_BUFSIZE <= WSIZE, it is never too late to\n\t\t\t// transform a block into a stored block.\n\t\t\tsend_bits((STORED_BLOCK << 1) + eof, 3);  /* send block type */\n\t\t\tbi_windup();         /* align on byte boundary */\n\t\t\tput_short(stored_len);\n\t\t\tput_short(~stored_len);\n\n\t\t\t// copy block\n\t\t\t/*\n\t\t\t\tp = &window[block_start];\n\t\t\t\tfor (i = 0; i < stored_len; i++) {\n\t\t\t\t\tput_byte(p[i]);\n\t\t\t\t}\n\t\t\t*/\n\t\t\tfor (i = 0; i < stored_len; i++) {\n\t\t\t\tput_byte(window[block_start + i]);\n\t\t\t}\n\t\t} else if (static_lenb === opt_lenb) {\n\t\t\tsend_bits((STATIC_TREES << 1) + eof, 3);\n\t\t\tcompress_block(static_ltree, static_dtree);\n\t\t} else {\n\t\t\tsend_bits((DYN_TREES << 1) + eof, 3);\n\t\t\tsend_all_trees(l_desc.max_code + 1, d_desc.max_code + 1, max_blindex + 1);\n\t\t\tcompress_block(dyn_ltree, dyn_dtree);\n\t\t}\n\n\t\tinit_block();\n\n\t\tif (eof !== 0) {\n\t\t\tbi_windup();\n\t\t}\n\t}\n\n\t/* ==========================================================================\n\t * Save the match info and tally the frequency counts. Return true if\n\t * the current block must be flushed.\n\t *\n\t * @param dist- distance of matched string\n\t * @param lc- (match length - MIN_MATCH) or unmatched char (if dist === 0)\n\t */\n\tfunction ct_tally(dist, lc) {\n\t\tl_buf[last_lit++] = lc;\n\t\tif (dist === 0) {\n\t\t\t// lc is the unmatched char\n\t\t\tdyn_ltree[lc].fc++;\n\t\t} else {\n\t\t\t// Here, lc is the match length - MIN_MATCH\n\t\t\tdist--; // dist = match distance - 1\n\t\t\t// Assert((ush)dist < (ush)MAX_DIST && (ush)lc <= (ush)(MAX_MATCH-MIN_MATCH) && (ush)D_CODE(dist) < (ush)D_CODES,  \"ct_tally: bad match\");\n\n\t\t\tdyn_ltree[length_code[lc] + LITERALS + 1].fc++;\n\t\t\tdyn_dtree[D_CODE(dist)].fc++;\n\n\t\t\td_buf[last_dist++] = dist;\n\t\t\tflags |= flag_bit;\n\t\t}\n\t\tflag_bit <<= 1;\n\n\t\t// Output the flags if they fill a byte\n\t\tif ((last_lit & 7) === 0) {\n\t\t\tflag_buf[last_flags++] = flags;\n\t\t\tflags = 0;\n\t\t\tflag_bit = 1;\n\t\t}\n\t\t// Try to guess if it is profitable to stop the current block here\n\t\tif (compr_level > 2 && (last_lit & 0xfff) === 0) {\n\t\t\t// Compute an upper bound for the compressed length\n\t\t\tvar out_length = last_lit * 8;\n\t\t\tvar in_length = strstart - block_start;\n\t\t\tvar dcode;\n\n\t\t\tfor (dcode = 0; dcode < D_CODES; dcode++) {\n\t\t\t\tout_length += dyn_dtree[dcode].fc * (5 + extra_dbits[dcode]);\n\t\t\t}\n\t\t\tout_length >>= 3;\n\t\t\t// Trace((stderr,\"\\nlast_lit %u, last_dist %u, in %ld, out ~%ld(%ld%%) \", encoder->last_lit, encoder->last_dist, in_length, out_length, 100L - out_length*100L/in_length));\n\t\t\tif (last_dist < parseInt(last_lit / 2, 10) && out_length < parseInt(in_length / 2, 10)) {\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\t\treturn (last_lit === LIT_BUFSIZE - 1 || last_dist === DIST_BUFSIZE);\n\t\t// We avoid equality with LIT_BUFSIZE because of wraparound at 64K\n\t\t// on 16 bit machines and because stored blocks are restricted to\n\t\t// 64K-1 bytes.\n\t}\n\n\t  /* ==========================================================================\n\t   * Send the block data compressed using the given Huffman trees\n\t   *\n\t   * @param ltree- literal tree\n\t   * @param dtree- distance tree\n\t   */\n\tfunction compress_block(ltree, dtree) {\n\t\tvar dist; // distance of matched string\n\t\tvar lc; // match length or unmatched char (if dist === 0)\n\t\tvar lx = 0; // running index in l_buf\n\t\tvar dx = 0; // running index in d_buf\n\t\tvar fx = 0; // running index in flag_buf\n\t\tvar flag = 0; // current flags\n\t\tvar code; // the code to send\n\t\tvar extra; // number of extra bits to send\n\n\t\tif (last_lit !== 0) {\n\t\t\tdo {\n\t\t\t\tif ((lx & 7) === 0) {\n\t\t\t\t\tflag = flag_buf[fx++];\n\t\t\t\t}\n\t\t\t\tlc = l_buf[lx++] & 0xff;\n\t\t\t\tif ((flag & 1) === 0) {\n\t\t\t\t\tSEND_CODE(lc, ltree); /* send a literal byte */\n\t\t\t\t\t//\tTracecv(isgraph(lc), (stderr,\" '%c' \", lc));\n\t\t\t\t} else {\n\t\t\t\t\t// Here, lc is the match length - MIN_MATCH\n\t\t\t\t\tcode = length_code[lc];\n\t\t\t\t\tSEND_CODE(code + LITERALS + 1, ltree); // send the length code\n\t\t\t\t\textra = extra_lbits[code];\n\t\t\t\t\tif (extra !== 0) {\n\t\t\t\t\t\tlc -= base_length[code];\n\t\t\t\t\t\tsend_bits(lc, extra); // send the extra length bits\n\t\t\t\t\t}\n\t\t\t\t\tdist = d_buf[dx++];\n\t\t\t\t\t// Here, dist is the match distance - 1\n\t\t\t\t\tcode = D_CODE(dist);\n\t\t\t\t\t//\tAssert (code < D_CODES, \"bad d_code\");\n\n\t\t\t\t\tSEND_CODE(code, dtree); // send the distance code\n\t\t\t\t\textra = extra_dbits[code];\n\t\t\t\t\tif (extra !== 0) {\n\t\t\t\t\t\tdist -= base_dist[code];\n\t\t\t\t\t\tsend_bits(dist, extra); // send the extra distance bits\n\t\t\t\t\t}\n\t\t\t\t} // literal or match pair ?\n\t\t\t\tflag >>= 1;\n\t\t\t} while (lx < last_lit);\n\t\t}\n\n\t\tSEND_CODE(END_BLOCK, ltree);\n\t}\n\n\t/* ==========================================================================\n\t * Send a value on a given number of bits.\n\t * IN assertion: length <= 16 and value fits in length bits.\n\t *\n\t * @param value- value to send\n\t * @param length- number of bits\n\t */\n\tvar Buf_size = 16; // bit size of bi_buf\n\tfunction send_bits(value, length) {\n\t\t// If not enough room in bi_buf, use (valid) bits from bi_buf and\n\t\t// (16 - bi_valid) bits from value, leaving (width - (16-bi_valid))\n\t\t// unused bits in value.\n\t\tif (bi_valid > Buf_size - length) {\n\t\t\tbi_buf |= (value << bi_valid);\n\t\t\tput_short(bi_buf);\n\t\t\tbi_buf = (value >> (Buf_size - bi_valid));\n\t\t\tbi_valid += length - Buf_size;\n\t\t} else {\n\t\t\tbi_buf |= value << bi_valid;\n\t\t\tbi_valid += length;\n\t\t}\n\t}\n\n\t/* ==========================================================================\n\t * Reverse the first len bits of a code, using straightforward code (a faster\n\t * method would use a table)\n\t * IN assertion: 1 <= len <= 15\n\t *\n\t * @param code- the value to invert\n\t * @param len- its bit length\n\t */\n\tfunction bi_reverse(code, len) {\n\t\tvar res = 0;\n\t\tdo {\n\t\t\tres |= code & 1;\n\t\t\tcode >>= 1;\n\t\t\tres <<= 1;\n\t\t} while (--len > 0);\n\t\treturn res >> 1;\n\t}\n\n\t/* ==========================================================================\n\t * Write out any remaining bits in an incomplete byte.\n\t */\n\tfunction bi_windup() {\n\t\tif (bi_valid > 8) {\n\t\t\tput_short(bi_buf);\n\t\t} else if (bi_valid > 0) {\n\t\t\tput_byte(bi_buf);\n\t\t}\n\t\tbi_buf = 0;\n\t\tbi_valid = 0;\n\t}\n\n\tfunction qoutbuf() {\n\t\tvar q, i;\n\t\tif (outcnt !== 0) {\n\t\t\tq = new_queue();\n\t\t\tif (qhead === null) {\n\t\t\t\tqhead = qtail = q;\n\t\t\t} else {\n\t\t\t\tqtail = qtail.next = q;\n\t\t\t}\n\t\t\tq.len = outcnt - outoff;\n\t\t\t// System.arraycopy(outbuf, outoff, q.ptr, 0, q.len);\n\t\t\tfor (i = 0; i < q.len; i++) {\n\t\t\t\tq.ptr[i] = outbuf[outoff + i];\n\t\t\t}\n\t\t\toutcnt = outoff = 0;\n\t\t}\n\t}\n\n\tfunction deflate(arr, level) {\n\t\tvar i, j, buff;\n\n\t\tdeflate_data = arr;\n\t\tdeflate_pos = 0;\n\t\tif (typeof level === \"undefined\") {\n\t\t\tlevel = DEFAULT_LEVEL;\n\t\t}\n\t\tdeflate_start(level);\n\n\t\tbuff = [];\n\n\t\tdo {\n\t\t\ti = deflate_internal(buff, buff.length, 1024);\n\t\t} while (i > 0);\n\n\t\tdeflate_data = null; // G.C.\n\t\treturn buff;\n\t}\n\n\tmodule.exports = deflate;\n\tmodule.exports.DEFAULT_LEVEL = DEFAULT_LEVEL;\n}());\n\n\n//////////////////\n// WEBPACK FOOTER\n// ../node_modules/deflate-js/lib/rawdeflate.js\n// module id = 6\n// module chunks = 0\n\n//# sourceURL=webpack:///../node_modules/deflate-js/lib/rawdeflate.js?");

/***/ })
/******/ ]);